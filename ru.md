# Глава 1. Введение в конкурентность

---

Конкурентность — интересное понятие, потому что в нашей сфере оно означает разное для разных людей. Помимо слова «конкурентность», вы могли слышать термины «асинхронность», «параллелизм» или «многопоточность». Некоторые считают их синонимами, другие же строго разграничивают их значения. Поскольку мы посвятим конкурентности целую книгу, полезно сначала разобраться, что именно мы подразумеваем под этим термином.

В главе 2 мы подробнее рассмотрим философию конкурентности, но пока примем практическое определение, которое станет основой для нашего понимания.

Когда большинство людей говорят о «конкурентности», они обычно имеют в виду процесс, выполняемый одновременно с одним или несколькими другими процессами. При этом подразумевается, что все эти процессы продвигаются примерно в одно и то же время. Простой аналогией могут быть люди: прямо сейчас вы читаете это предложение, а другие в мире одновременно живут своей жизнью. Они существуют конкурентно по отношению к вам.

Конкурентность — обширная тема в компьютерных науках, и из этого определения вытекает множество аспектов: теория, моделирование конкурентности, корректность логики, практические проблемы и даже теоретическая физика! В книге мы затронем некоторые смежные темы, но сосредоточимся в основном на практических вопросах, связанных с конкурентностью в контексте Go. А именно: как Go моделирует конкурентность, какие проблемы возникают из этой модели и как можно комбинировать её примитивы для решения задач.

В этой главе мы в общих чертах рассмотрим, почему конкурентность стала столь важной темой в компьютерных науках, почему она сложна и требует тщательного изучения, а главное — как, несмотря на эти трудности, Go позволяет делать программы понятнее и быстрее благодаря своим примитивам конкурентности.

Как и в любом исследовании, начнём с истории. Давайте сначала разберёмся, почему конкурентность приобрела такое важное значение.

## Закон Мура, веб-масштабируемость и проблемы, в которых мы оказались

В 1965 году Гордон Мур опубликовал трёхстраничную статью, в которой предсказал консолидацию рынка электроники вокруг интегральных схем и удвоение количества компонентов в схемах каждый год на протяжении как минимум десятилетия. В 1975 году он скорректировал своё предсказание, утверждая, что количество компонентов на интегральной схеме будет удваиваться каждые два года. Это предсказание оставалось верным вплоть до недавнего времени — примерно до 2012 года.

Несколько компаний предвидели замедление темпов роста, предусмотренного законом Мура, и начали исследовать альтернативные способы повышения вычислительной мощности. Как говорится, необходимость — мать изобретений, и именно таким образом были созданы многоядерные процессоры.

Это выглядело как умное решение проблемы ограничения закона Мура, однако вскоре компьютерные учёные столкнулись с ограничениями другого закона: закона Амдала, названного в честь архитектора компьютеров Джина Амдала.

Закон Амдала описывает потенциальный прирост производительности при параллельном решении задачи. Проще говоря, он утверждает, что этот прирост ограничен скоростью работы программы, которую нельзя распараллелить

### Пример 1: Программа с графическим интерфейсом

Представьте приложение с GUI: пользователь видит интерфейс, нажимает кнопки, и что-то происходит. Здесь критическая часть конвейера — взаимодействие с человеком — строго последовательна. Сколько бы ядер вы ни добавили, программа всё равно будет ограничена скоростью реакции пользователя.

### Пример 2: Вычисление цифр числа π

Благодаря spigot-алгоритмам, эта задача относится к «заведомо параллельным» (англ. embarrassingly parallel). Это технический термин (да, звучит странно), означающий, что задачу легко разбить на независимые подзадачи. Здесь добавление ядер значительно ускорит вычисления, а сложность сместится к агрегации результатов.

Закон Амдала помогает понять разницу между такими задачами и решить, стоит ли распараллеливание усилий.

Для заведомо параллельных задач рекомендуется горизонтальное масштабирование: запуск копий программы на дополнительных CPU или машинах для сокращения времени выполнения. Такие задачи идеально подходят для этого подхода, так как их легко разбить на части для распределённой обработки.

В начале 2000-х горизонтальное масштабирование упростилось благодаря облачным вычислениям. Хотя термин появился ещё в 1970-х, именно тогда он стал мейнстримом. Облака предложили новый масштаб: вместо ручного управления серверами разработчики получили доступ к пулам ресурсов, которые динамически выделялись под задачи. Машины стали «эфемерными», настраиваемыми под конкретные нагрузки и задачи, и часто размещались в дата-центрах сторонних компаний.

Это породило новую парадигму мышления: теперь у разработчиков был дешёвый доступ к огромным вычислительным мощностям. Решения могли охватывать сотни машин и географических регионов, делая технологии, ранее доступные только гигантам вроде Google, достоянием всех.

Однако облака принесли и проблемы:

- Оркестрация ресурсов
- Обмен данными между инстансами
- Агрегация и хранение результатов.

Но сложнее всего оказалось правильно смоделировать конкурентный код. Распределённость системы усугубила типичные проблемы параллелизма. Успешное решение этих задач породило новый стандарт — web scale.
Web-scale-программы — это, среди прочего, заведомо параллельные системы, способные обрабатывать сотни тысяч запросов в секунду за счёт добавления инстансов. Это обеспечило:

- Бесшовные обновления,
- Гибкую масштабируемость,
- Геораспределённость.

Но также добавило сложностей в понимании кода и отказоустойчивости.

И вот мы оказываемся в этом мире — мире многоядерных процессоров, облачных вычислений, веб-масштабируемости и задач, которые могут быть как распараллелены, так и нет. Современный разработчик зачастую чувствует себя несколько подавленным. Эстафетная палочка передана нам, и теперь именно мы должны решать задачи в рамках тех аппаратных ограничений, которые имеем.

В 2005 году Херб Саттер написал знаковую статью для Dr. Dobb's под названием «Бесплатный обед закончен: фундаментальный поворот к конкурентности в программном обеспечении». Название оказалось пророческим. В конце статьи Саттер делает важное заявление:

«Нам отчаянно необходима более высокоуровневая модель конкурентности, чем та, что предлагают современные языки программирования»
Чтобы понять, почему Саттер использует такие сильные выражения, нужно разобраться, почему конкурентность так сложно реализовать правильно.

## Почему конкурентность это сложно?

Работа с конкурентным кодом печально известна своей сложностью. Обычно требуется несколько итераций, чтобы заставить его работать как задумано. Но даже тогда нередки случаи, когда ошибки остаются незамеченными годами, пока изменение условий (возросшая нагрузка на диск, больше пользователей в системе и т.д.) не вызовет проявление ранее скрытого бага. Кстати, для примеров кода в этой книге я привлек максимальное количество рецензентов, чтобы минимизировать такие проблемы.

К счастью, все разработчики сталкиваются с одинаковыми проблемами при работе с конкурентным кодом. Благодаря этому знатоки computer science смогли классифицировать типичные проблемы, что позволяет нам обсуждать причины их возникновения и способы решения.

Давайте рассмотрим основные проблемы, которые делают работу с конкурентным кодом одновременно сложной и интересной:

## Состояние гонки (Race Conditions)

Состояние гонки возникает, когда две или более операций должны выполняться в строго определённом порядке, но программа не гарантирует соблюдение этого порядка выполнения.

Чаще всего это проявляется в так называемой "гонке данных" (data race), когда одна конкурентная операция пытается прочитать переменную, в то время как в какой-то неопределённый момент времени другая конкурентная операция пытается записать значение в эту же переменную.

Приведём простой пример:
```go
var data int
go func() {
    data++
}()
if data == 0 {
    fmt.Printf("the value is %v.\n", data)
}
```

В Go для параллельного выполнения функций используется ключевое слово go, которое создает так называемую горутину (подробнее в разделе "Горутины").

Рассмотрим пример, где строки 3 и 5 пытаются получить доступ к переменной data без гарантии порядка выполнения. Возможные сценарии выполнения:

- Ничего не выводится - строка 3 выполнилась до строки 5
- Выводится "the value is 0" - строки 5-6 выполнились до строки 3
- Выводится "the value is 1" - строка 5 выполнилась до 3, но 3 выполнилась до 6

## Почему возникают гонки данных? (race conditions)

Как вы можете видеть, всего несколько строк неправильного кода могут внести огромную нестабильность
в вашу программу.

В большинстве случаев гонки данных возникают, потому что разработчики думают о
коде последовательно. Они предполагают, что поскольку строка кода находится перед другой,
она будет запущена первой. Они предполагают, что вышеприведенная горутина будет запланирована и выполнена
до того, как переменная data будет прочитана в операторе if.

При написании параллельного кода вам нужно тщательно перебирать возможные
сценарии. Если вы не используете некоторые из методов, которые мы рассмотрим далее в книге,
у вас нет гарантий, что ваш код будет запущен в том порядке, в котором он указан в исходном
коде.

Иногда я нахожу полезным представить, что между вызываемыми операциями проходит большой период.
Представьте, что между вызовом горутины и ее выполнением пройдет час. Как тогда поведет себя оставшаяся часть кода?
А что, если бы между успешным выполнением горутины и достижением программой оператора if
прошел час?
Мне помогает такой подход, потому что для компьютера масштаб может быть
другим, но смысл от этого не теряется.
Но такая мысль приводит разработчика в ловушку разбрасывания sleep по всему коду. Как им кажется, это решает проблемы с параллелизмом. Давайте попробуем это в предыдущей программе:

```go
var data int
go func() { data++ }()
time.Sleep(1*time.Second) // This is bad!
if data == 0 {
    fmt.Printf("the value is %v.\n" data)
}
```

Решили ли мы нашу гонку данных? Нет. На самом деле, все три результата все еще могут возникнуть из этой программы, просто это становится все менее вероятным. Чем дольше мы спим между вызовом нашей горутины и проверкой значения данных, тем ближе наша программа становится к достижению корректности, но эта вероятность асимптотически приближается к логической корректности; она никогда не будет логически корректной.
В дополнение к этому, мы теперь внесли неэффективность в наш алгоритм. Теперь нам нужно спать одну секунду, чтобы повысить вероятность того, что мы не увидим нашу гонку данных. Если бы мы использовали правильные инструменты, нам, возможно, вообще не пришлось бы ждать, или ожидание могло бы составлять всего
микросекунду.
Вывод здесь в том, что вы всегда должны стремиться к логической корректности. 

Внедрение time.Sleep() в ваш код может быть удобным способом отладки параллельных программ, но это не решение.

Состояние гонки — один из самых коварных типов ошибок параллелизма, потому что они
могут не проявляться до тех пор, пока код не будет запущен в производство. Они
обычно вызваны изменением среды, в которой выполняется код, или
беспрецедентным событием. В этих случаях код, кажется, ведет себя правильно,
но на самом деле существует просто очень высокая вероятность того, что операции будут выполнены в
порядке. Рано или поздно программа будет иметь непредвиденные последствия.

## Атомарность

Когда что-то считается атомарным или имеет свойство атомарности, это
означает, что в контексте, в котором оно работает, оно неделимо или непрерываемо.

Так что же это на самом деле означает, и почему это важно знать при работе с
параллельным кодом?

Первое, что очень важно, — это слово «контекст». Что-то может быть атомарным
в одном контексте, но не в другом. Операции, которые являются атомарными в контексте вашего
процесса, могут не быть атомарными в контексте операционной системы; операции, которые являются
атомарными в контексте операционной системы, могут не быть атомарными в контексте вашей
машины; и операции, которые являются атомарными в контексте вашей
машины, могут не быть атомарными в контексте вашего приложения. Другими словами,
атомарность операции может меняться в зависимости от текущей определенной области действия.
Этот факт может работать как за, так и против вас!

Когда вы думаете об атомарности, очень часто первое, что вам нужно сделать, это определить
контекст или область действия, в которой операция будет считаться атомарной. Все
следует из этого.

---
### Интересный факт

В 2006 году игровая компания Blizzard успешно подала в суд на MDY Industries на
6 000 000 долларов США за создание программы под названием «Glider», которая автоматически
играла в их игру World of Warcraft без вмешательства пользователя. Такие типы программ обычно называют «ботами» (сокращение от robots).
В то время в World of Warcraft была античит-программа под названием «Warden», которая
запускалась в любое время, когда вы играли в игру. Помимо прочего, Warden сканировал
память хост-машины и запускал эвристику для поиска программ,
которые, по-видимому, использовались для мошенничества.
Glider успешно избежал этой проверки, воспользовавшись концепцией атомарного
контекста. Warden считал сканирование памяти на машине атомарной операцией, но Glider использовал аппаратные прерывания, чтобы скрыть себя до начала этого сканирования! Сканирование памяти Уорденом было атомарным в контексте процесса, но не в контексте операционной системы.

---

Теперь давайте рассмотрим термины «неделимый» и «непрерываемый». Эти термины означают, что
в контексте, который вы определили, что-то, что является атомарным, произойдет полностью,
без того, чтобы что-либо происходило в этом контексте одновременно. Это все еще труднопроизносимо, поэтому
давайте рассмотрим пример:
```go
i++
```

Это такой простой пример, какой только можно придумать, и тем не менее он легко демонстрирует концепцию атомарности. Он может выглядеть атомарным, но краткий анализ показывает несколько операций:
- Извлечь значение i.
- Увеличить значение i.
- Сохранение значения i.

Хотя каждая из этих операций по отдельности является атомарной, комбинация этих трех может
не быть таковой, в зависимости от вашего контекста. Это раскрывает интересное свойство атомарных операций: их объединение не обязательно приводит к более крупной атомарной операции. Сделать операцию атомарной зависит от того, в каком контексте вы хотите, чтобы она была атомарной. Если ваш контекст — это программа без параллельных процессов, то этот код является
атомарным в этом контексте. Если ваш контекст — это goroutine, которая не раскрывает i
другим goroutine, то этот код является атомарным.

Так почему же нас это волнует? Атомарность важна, потому что если что-то является атомарным, то неявно
оно безопасно в параллельных контекстах. Это позволяет нам составлять логически правильные программы и, как мы увидим позже, может даже служить способом оптимизации параллельных программ.

Большинство операторов не являются атомарными, не говоря уже о функциях, методах и программах.
Если атомарность является ключом к составлению логически правильных программ, а большинство операторов не являются
атомарными, как нам согласовать эти два оператора? Мы углубимся в это позже, но
говоря короче, мы можем форсировать атомарность, используя различные методы. 
Суть данного искусства - определить, какие области вашего кода должны быть атомарными и на каком уровне
детализации. Некоторые из этих проблем мы обсудим в следующем разделе.

## Синхронизация доступа к памяти.

Допустим, у нас есть гонка данных: два параллельных процесса пытаются получить доступ к
одной и той же области памяти, и способ, которым они получают доступ к памяти, не является атомарным. Наш
предыдущий пример простой гонки данных будет работать хорошо с несколькими модификациями:

```go
var data int
go func() { data++}()
if data == 0 {
fmt.Println("the value is 0.")
} else {
fmt.Printf("the value is %v.\n", data)
}
```

Мы добавили здесь предложение else, чтобы независимо от значения данных мы всегда
получали какой-то вывод. Помните, что, как написано, есть гонка данных, и вывод программы будет полностью недетерминированным.

На самом деле, есть название для раздела вашей программы, которому нужен исключительный доступ к
общему ресурсу. Это называется критической секцией(критическим разделом). В этом примере у нас есть три критических секции:

- Наша goroutine, которая увеличивает переменные data.
- Наш оператор if, который проверяет, равно ли значение data нулю.
- Наш оператор fmt.Printf, который извлекает значение data для вывода.

Существуют различные способы защиты критических секций вашей программы, и у Go есть несколько
лучших идей, как с этим справиться, но один из способов решения этой проблемы — синхронизировать доступ к памяти между вашими критическими разделами. Давайте посмотрим, как это
выглядит. 

Следующий код не является идиоматическим Go (и я не предлагаю вам пытаться решать ваши
проблемы гонки данных таким образом), но он очень просто демонстрирует синхронизацию доступа к памяти. Если какие-либо типы, функции или методы в этом примере вам незнакомы, это нормально. Сосредоточьтесь на концепции синхронизации доступа к памяти, следуя выноскам.

```go
var memoryAccess sync.Mutex // 1
var value int
go func() {
    memoryAccess.Lock() // 2
    value++
    memoryAccess.Unlock() // 3
}()
memoryAccess.Lock() // 4
if value == 0 {
    fmt.Printf("the value is %v.\n", value)
} else {
    fmt.Printf("the value is %v.\n", value)
}
memoryAccess.Unlock() // 5
```
1) Здесь мы добавляем переменную, которая позволит нашему коду синхронизировать доступ к памяти переменной data. Мы подробно рассмотрим тип sync.Mutex в разделе «Пакет sync».
2) Здесь мы объявляем, что пока мы не объявим иное, наша goroutine должна иметь
исключительный доступ к этой памяти.
3) Здесь мы объявляем, что goroutine закончила работу с этой памятью.
4) Здесь мы снова объявляем, что следующие условные операторы должны иметь
исключительный доступ к памяти переменной data.
5) Здесь мы объявляем, что мы снова закончили работу с этой памятью.

В этом примере мы создали соглашение, которому должны следовать разработчики. В любое время, когда разработчики хотят получить доступ к памяти переменной данных, они должны сначала вызвать Lock, а когда закончат, они должны вызвать Unlock. Код между этими двумя операторами может
предположить, что у него есть исключительный доступ к данным; мы успешно синхронизировали доступ к
памяти. Также обратите внимание, что если разработчики не следуют этому соглашению, у нас нет гарантии исключительного доступа! Мы вернемся к этой идее в разделе «Ограничение».

Вы могли заметить, что хотя мы решили нашу гонку данных, мы на самом деле не решили наше состояние гонки! Порядок операций в этой программе по-прежнему недетерминирован; мы просто немного сузили область недетерминизма. В этом примере либо горутина выполнится первой, либо оба наших блока if и else. Мы по-прежнему
не знаем, что произойдет первым при любом заданном выполнении этой программы. Позже мы рассмотрим инструменты для правильного решения подобных проблем.

На первый взгляд это кажется довольно простым: если вы обнаружили, что у вас есть критические разделы, добавьте точки
для синхронизации доступа к памяти! Легко, не так ли? Ну... в некотором роде.

Это правда, что вы можете решить некоторые проблемы, синхронизировав доступ к памяти,
но, как мы только что увидели, это не решает гонки данных или логическую корректность. Кроме того, это также может создавать проблемы с обслуживанием и производительностью.

Обратите внимание, что ранее мы упоминали, что создали соглашение для объявления нам
необходимо исключительное право доступа к некоторой памяти. Соглашения хороши, но их также легко
игнорировать, особенно в разработке программного обеспечения, где требования бизнеса иногда перевешивают благоразумие. Синхронизируя доступ к памяти таким образом,
вы рассчитываете, что все другие разработчики будут следовать этому соглашению сейчас и в будущем. Это довольно сложная задача. К счастью, далее в этой книге мы также рассмотрим
некоторые способы, которыми мы можем помочь нашим коллегам добиться большего успеха.

Таким образом синхронизация доступа к памяти также имеет последствия для производительности. Мы сохраним ньюансы для дальнейшего изучения пакета синхронизации в разделе «Пакет синхронизации», но вызовы Lock, которые вы видите, могут замедлить нашу программу. Каждый раз, когда мы выполняем одну из этих операций, наша программа останавливается на некоторое время. Это поднимает два вопроса:
- Мои критические разделы входят и выходят из них повторно?
- Какого размера должны быть мои критические разделы?

Ответить на эти два вопроса в контексте вашей программы — это искусство, и это добавляет сложности в синхронизацию доступа к памяти.
Синхронизация доступа к памяти также имеет некоторые общие проблемы с другими методами моделирования параллельных задач, и мы обсудим их в следующем разделе.

## Deadlocks, Livelocks, and Starvation. Взаимоблокировки, блокировки в режиме реального времени и голодание

В предыдущих разделах обсуждалось корректное выполнение программы, поскольку, если
возникающие проблемы решаются правильно, ваша программа никогда не даст неверного ответа.

К сожалению, даже если вы успешно справитесь с этими классами проблем, есть еще один
класс проблем, с которыми нужно бороться: взаимоблокировки, блокировки в режиме реального времени и голодание. 
Все эти проблемы влияют на гарантию того, что ваша программа всегда выполняет что-то полезное. Если с ними не справиться должным образом, ваша программа может войти в состояние, в котором она вообще перестанет функционировать.

### Deadlock(Взаимоблокировка)

Взаимоблокированная программа — это программа, в которой все параллельные процессы ждут друг друга. В этом состоянии программа никогда не восстановится без внешнего вмешательства.

Если это звучит страшно, то так оно и есть! Go runtime пытается выполнить свою часть работы и
обнаружит некоторые взаимоблокировки (все горутины должны быть заблокированы или «спящими»), но это не
сильно поможет вам предотвратить взаимоблокировки.

Чтобы помочь закрепить, что такое взаимоблокировка, давайте сначала рассмотрим пример. Опять же, пока игнорируйте
любые типы, функции, методы или пакеты, которые вы не знаете, и просто следуйте
выноскам кода

```go
type value struct {
    mu sync.Mutex
    value int
}

var wg sync.WaitGroup
printSum := func(v1, v2 *value) {
    defer wg.Done()
    v1.mu.Lock() // 1
    defer v1.mu.Unlock() // 2
	
    time.Sleep(2*time.Second) //3
    v2.mu.Lock()
    defer v2.mu.Unlock()
	
    fmt.Printf("sum=%v\n", v1.value + v2.value)
}

var a, b value
wg.Add(2)
go printSum(&a, &b)
go printSum(&b, &a)
wg.Wait()
```

1) Здесь мы пытаемся войти в критическую секцию для входящего значения.
2) Здесь мы используем оператор defer для выхода из критической секции до возврата printSum.
3) Здесь мы спим в течение определенного периода времени, чтобы имитировать работу (и вызвать взаимоблокировку).

4) Если бы вы попытались запустить этот код, вы, вероятно, увидели бы:
фатальная ошибка: все горутины спят — взаимоблокировка!
Почему? Если вы посмотрите внимательно, вы увидите проблему синхронизации в этом коде. Ниже приведено графическое представление того, что происходит. Прямоугольники представляют функции, горизонтальные
линии — вызовы этих функций, а вертикальные
полосы — время жизни функции в начале
графика (рисунок 1-1).

![img.png](img/1-1.png)

По сути, мы создали две шестеренки, которые не могут вращаться вместе: наш первый вызов print
Sum блокирует a, а затем пытается заблокировать b, но в то же время наш второй вызов print
Sum заблокировал b и попытался заблокировать a. Обе горутины бесконечно ждут друг
друга.

---
### Irony

Чтобы упростить этот пример, я использую time.Sleep для запуска взаимоблокировки. Однако, это вводит состояние гонки! Можете ли вы его найти?
Логически «идеальная» взаимоблокировка потребует правильной синхронизации.(На самом деле у нас нет гарантии, в каком порядке будут запущены горутины или сколько времени им потребуется для запуска.
Возможно, хотя и маловероятно, что одна горутина может получить и снять обе блокировки до начала работы другой,
тем самым избежав deadlock-а!)

---

Кажется довольно очевидным, почему возникает эта взаимоблокировка, когда мы представляем ее графически,
но мы бы выиграли от более строгого определения. 

Оказывается, есть
несколько условий, которые должны присутствовать для возникновения взаимоблокировок, и в 1971 году Эдгар Коффман перечислил эти условия в своей статье. Эти условия теперь известны как
Условия Коффмана и являются основой для методов, которые помогают обнаруживать, предотвращать и
исправлять взаимоблокировки.

Условия Коффмана следующие:
- Взаимное исключение. Параллельный процесс имеет исключительные права на ресурс в любой момент времени.
- Условие ожидания. Параллельный процесс должен одновременно удерживать ресурс и ожидать
дополнительный ресурс.
- Нет вытеснения. Ресурс, удерживаемый параллельным процессом, может быть освобожден только этим процессом,
поэтому он удовлетворяет этому условию.
- Круговое ожидание. Конкурентный процесс (P1) должен ожидать цепочку других конкурентных процессов (P2), которые в свою очередь ждут его (P1), поэтому он удовлетворяет этому последнему условию

Давайте рассмотрим нашу придуманную программу и определим, соответствует ли она всем четырем условиям:
1. Функция printSum требует исключительных прав как на a, так и на b, поэтому она
   выполняет это условие.
2. Поскольку printSum удерживает либо a, либо b и ожидает второго, она
   выполняет это условие.
3. Мы не дали возможности нашим горутинам быть вытесненными.
4. Наш первый вызов printSum ожидает нашего второго вызова, и наоборот.

Да, у нас определенно есть взаимоблокировка.

Эти законы также позволяют нам предотвращать взаимоблокировки. Если мы гарантируем, что хотя бы одно из этих
условий не выполняется, мы можем предотвратить возникновение взаимоблокировок. К сожалению, на практике эти условия может быть трудно рассуждать, и, следовательно, их трудно предотвратить. Интернет усеян вопросами от разработчиков, таких как вы и я, которые задаются вопросом,
почему фрагмент кода взаимоблокируется. Обычно это довольно очевидно, когда кто-то указывает на это, но часто это требует еще одной пары глаз. Мы поговорим о том, почему это так, в разделе «Определение безопасности параллелизма».

## Livelock
Livelock — это программы, которые активно выполняют параллельные операции, но эти
операции ничего не делают для продвижения состояния программы вперед.

Вы когда-нибудь были в коридоре, идя к другому человеку? Она отходит в одну
сторону, чтобы пропустить вас, но вы только что сделали то же самое. Поэтому вы отходите в другую сторону, но
она тоже сделала то же самое. Представьте, что это продолжается вечно, и вы поймете livelock.

Давайте напишем код, который поможет продемонстрировать этот сценарий. Сначала мы настроим
несколько вспомогательных функций, которые упростят пример. Чтобы получить работающий
пример, в коде здесь используется несколько тем, которые мы еще не рассмотрели. Я не советую
пытаться понять его подробно, пока вы не освоите пакет синхронизации. Вместо этого я рекомендую следовать выноскам кода, чтобы понять основные моменты, а затем обратить внимание на второй блок кода, который содержит
суть примера.

```go
cadence := sync.NewCond(&sync.Mutex{})
go func() {
   for range time.Tick(1*time.Millisecond) {
    cadence.Broadcast()
   }
}()

takeStep := func() {
   cadence.L.Lock()
   cadence.Wait()
   cadence.L.Unlock()
}

tryDir := func(dirName string, dir *int32, out *bytes.Buffer) bool { // 1
   fmt.Fprintf(out, " %v", dirName)
   atomic.AddInt32(dir, 1) // 2
   takeStep() // 3
   if atomic.LoadInt32(dir) == 1 {
      fmt.Fprint(out, ". Success!")
      return true
   }
   takeStep()
   atomic.AddInt32(dir, -1) // 4
   return false
}

var left, right int32
tryLeft := func(out *bytes.Buffer) bool { return tryDir("left", &left, out) }
tryRight := func(out *bytes.Buffer) bool { return tryDir("right", &right, out) }
```

1) tryDir позволяет человеку попытаться двигаться в направлении и возвращает, были ли они успешными. Каждое направление представлено как количество людей, пытающихся двигаться в этом направлении, dir.
2) Сначала мы объявляем о своем намерении двигаться в направлении, увеличивая это направление на единицу. Мы подробно обсудим атомарный пакет в Главе 3. На данный момент все, что вам нужно знать, это то, что операции этого пакета являются атомарными.
3) Чтобы пример продемонстрировал оперативную блокировку, каждый человек должен двигаться с одинаковой скоростью, или каденсом. takeStep имитирует постоянный каденс между всеми участниками.
4) Здесь человек понимает, что он не может двигаться в этом направлении, и сдается. Мы указываем на это, уменьшая это направление на единицу.

```go
walk := func(walking *sync.WaitGroup, name string) {
   var out bytes.Buffer
   defer func() { fmt.Println(out.String()) }()
   defer walking.Done()
   
   fmt.Fprintf(&out, "%v is trying to scoot:", name)
   
   for i := 0; i < 5; i++ { // 1
      if tryLeft(&out) || tryRight(&out) { // 2
       return
      }
   }
   
   fmt.Fprintf(&out, "\n%v tosses her hands up in exasperation!", name)
}

var peopleInHallway sync.WaitGroup //3
peopleInHallway.Add(2)

go walk(&peopleInHallway, "Alice")
go walk(&peopleInHallway, "Barbara")

peopleInHallway.Wait()
```

1) Я установил искусственный предел на количество попыток, чтобы эта программа
завершилась. В программе, которая имеет оперативную блокировку, такого предела может не быть, поэтому
это проблема!
2) Сначала человек попытается сделать шаг влево, а если это не удается, он попытается сделать шаг
вправо.
3) Эта переменная предоставляет программе возможность ждать, пока оба человека
либо не смогут обойти друг друга, либо сдадутся.

Программа выведет:  
Alice is trying to scoot: left right left right left right left right left right   
Alice tosses her hands up in exasperation!  
Barbara is trying to scoot: left right left right left right left right
left right  
Barbara tosses her hands up in exasperation!

Вы можете видеть, что Алиса и Барбара продолжают мешать друг другу, прежде чем окончательно
сдаться.
Этот пример демонстрирует очень распространенную причину написания лайвлоков: два или более
одновременных процесса пытаются предотвратить тупик без координации. Если
люди в коридоре договорились друг с другом, что только один человек будет двигаться,
не было бы лайвлока: один человек стоял бы на месте, другой
двигался бы в другую сторону, и они продолжали бы идти.

По моему мнению, livelock сложнее обнаружить, чем deadlock, просто потому,
что может показаться, что программа выполняет работу. 

Если бы лайвлокированная программа работала на
вашей машине, и вы посмотрели на загрузку ЦП, чтобы определить, делает ли она что-нибудь, вы могли бы подумать, что это так. В зависимости от лайвлока она могла бы даже испускать другие сигналы, которые заставили бы вас думать, что она выполняет работу. И все же все это время ваша программа играла бы в вечную игру в коридорную перетасовку.
Livelocks — это подмножество более обширного набора проблем, называемых голоданием. Мы рассмотрим это далее.

## Starvation (Голодание)

Голодание — это любая ситуация, когда параллельный процесс не может получить все ресурсы, необходимые для выполнения работы.
Когда мы обсуждали блокировки, ресурс, которого не хватало каждой горутине, был
совместной блокировкой. Блокировки требуют отдельного обсуждения от голодания, потому что при блокировке все параллельные процессы одинаково голодают, и никакая работа не выполняется.
В более широком смысле, голодание обычно подразумевает, что есть один или несколько жадных параллельных процессов, которые несправедливо мешают одному или нескольким параллельным процессам
выполнять работу максимально эффективно или, может быть, вообще.
Вот пример программы с жадной горутиной и вежливой горутиной:

```go
var wg sync.WaitGroup
var sharedLock sync.Mutex
const runtime = 1*time.Second

greedyWorker := func() {
   defer wg.Done()
   var count int
   for begin := time.Now(); time.Since(begin) <= runtime; {
      sharedLock.Lock()
      time.Sleep(3*time.Nanosecond)
      sharedLock.Unlock()
      count++
   }
   fmt.Printf("Greedy worker was able to execute %v work loops\n", count)
}

politeWorker := func() {
   defer wg.Done()
   var count int
   for begin := time.Now(); time.Since(begin) <= runtime; {
      sharedLock.Lock()
      time.Sleep(1*time.Nanosecond)
      sharedLock.Unlock()
	  
      sharedLock.Lock()
      time.Sleep(1*time.Nanosecond)
      sharedLock.Unlock()
	  
      sharedLock.Lock()
      time.Sleep(1*time.Nanosecond)
      sharedLock.Unlock()
	  
      count++
   }
   fmt.Printf("Polite worker was able to execute %v work loops.\n", count)
}

wg.Add(2)
go greedyWorker()
go politeWorker()
wg.Wait()
```

Результат выполнения данной программы:  
Polite worker was able to execute 289777 work loops.  
Greedy worker was able to execute 471287 work loops

Жадный работник жадно удерживает общую блокировку на протяжении всего своего рабочего цикла, тогда как вежливый работник пытается заблокировать только тогда, когда это необходимо. Оба работника
выполняют одинаковый объем имитируемой работы (спя в течение трех наносекунд), но, как вы
можете видеть, за одинаковое количество времени жадный работник выполнил почти вдвое больше работы!

Если мы предположим, что у обоих работников критический раздел одинакового размера, вместо того, чтобы сделать вывод, что алгоритм жадного работника более эффективен (или что вызовы Lock и Unlock медленные — это не так), мы вместо этого придем к выводу, что жадный работник без необходимости расширил свое удержание общей блокировки за пределы своего критического раздела и мешает (через голодание) goroutine вежливого работника выполнять работу
эффективно.

Обратите внимание на нашу технику здесь для определения голодания: метрику. Голод является
хорошим аргументом для записи и выборки метрик. Один из способов обнаружить и решить проблему голодания — это записывать время выполнения работы, а затем определять,
настолько ли высока ваша скорость работы, как вы ожидаете.

---
### Поиск баланса

Стоит отметить, что предыдущий пример кода также может служить примером
производительности последствий синхронизации доступа к памяти. Поскольку синхронизация доступа к памяти обходится дорого, может быть выгодно расширить нашу
блокировку за пределы наших критических разделов. С другой стороны, делая это — как мы видели — мы
рискуем лишить другие параллельные процессы возможности.
Если вы используете синхронизацию доступа к памяти, вам придется найти баланс между
предпочтением грубой синхронизации для производительности и мелкой синхронизации для справедливости. Когда придет время настраивать производительность вашего приложения,
для начала я настоятельно рекомендую вам ограничить синхронизацию доступа к памяти только
критическими разделами; если синхронизация станет проблемой производительности, вы всегда можете расширить область действия. Гораздо сложнее пойти другим путем.
---

Итак, голодание может привести к тому, что ваша программа будет вести себя неэффективно или неправильно. Предыдущий
пример демонстрирует неэффективность, но если у вас есть параллельный процесс, который настолько
жаден, что полностью мешает другому параллельному процессу выполнять
работу, у вас на руках более серьезная проблема.
Мы также должны рассмотреть случай, когда голодание происходит извне процесса Go. Имейте в виду, что голодание может также применяться к ЦП, памяти, дескрипторам файлов,
подключениям к базе данных: любой общий ресурс, является кандидатом на голодание.

## Определение безопасности параллелизма

Определение безопасности параллелизма
Наконец, мы подошли к самому сложному аспекту разработки параллельного кода, к тому,
что лежит в основе всех остальных проблем: люди.    За каждой строкой кода стоит как минимум один
человек.

Как мы обнаружили, параллельный код сложен по множеству причин. Если вы разработчик и пытаетесь решить все эти проблемы, внедряя новую функциональность или исправляя ошибки в своей программе, может быть действительно сложно определить,
что делать правильно.
Если вы начинаете с чистого листа и вам нужно создать разумный способ моделирования
проблемного пространства, и задействован параллелизм, может быть сложно найти правильный уровень
абстракции. Как вы раскрываете параллелизм вызывающим? Какие методы вы
используете для создания решения, которое легко использовать и изменять? Каков правильный уровень
параллелизма для этой проблемы? Хотя есть способы структурированного мышления об этих проблемах, это остается искусством.

Как разработчик, взаимодействующий с существующим кодом, не всегда очевидно, какой код использует параллелизм, и как безопасно использовать код. Возьмем эту сигнатуру функции:
```go
// CalculatePi вычисляет цифры числа Pi между начальной и конечной
// позицией.
func CalculatePi(begin, end int64, pi *Pi)
```
Вычисление числа Pi с большой точностью лучше всего выполнять параллельно, но
этот пример вызывает много вопросов:
- Как мне это сделать с помощью этой функции?
- Я отвечаю за создание нескольких одновременных вызовов этой функции?
- Похоже, что все экземпляры функции будут работать непосредственно с экземпляром Pi, адрес которого я передаю; отвечаю ли я за синхронизацию доступа
к этой памяти, или тип Pi справляется с этим за меня?

Одна функция поднимает все эти вопросы. Представьте себе программу любого среднего размера, и
вы можете начать понимать сложности, которые может создавать параллелизм.

Комментарии могут творить чудеса здесь. Что, если бы функция CalculatePi была бы написана так:

```go
// CalculatePi calculates digits of Pi between the begin and end
// place.
//
// Internally, CalculatePi will create FLOOR((end-begin)/2) concurrent
// processes which recursively call CalculatePi. Synchronization of
// writes to pi are handled internally by the Pi struct.
func CalculatePi(begin, end int64, pi *Pi)
```

Теперь мы понимаем, что можем вызывать функцию просто и не беспокоиться о параллелизме или синхронизации. Важно, что комментарий охватывает следующие аспекты:
- Кто отвечает за параллелизм?
- Как проблемное пространство отображается на примитивы параллелизма?
- Кто отвечает за синхронизацию?

При раскрытии функций, методов и переменных в проблемных пространствах, которые включают параллелизм, сделайте своим коллегам и себе в будущем одолжение: отвлекитесь в сторону многословных комментариев и постарайтесь охватить эти три аспекта.

Также учтите, что, возможно, неоднозначность в этой функции предполагает, что мы неправильно ее смоделировали. Может быть, вместо этого нам следует использовать функциональный подход и убедиться, что наша функция не имеет побочных эффектов:
```go
func CalculatePi(begin, end int64) []uint
```
Одна только сигнатура этой функции снимает любые вопросы синхронизации, но все еще оставляет вопрос о том, используется ли параллелизм. Мы можем изменить сигнатуру
снова, чтобы выдать еще один сигнал о том, что происходит:
```go
func CalculatePi(begin, end int64) <-chan uint
```

Здесь мы видим первое использование того, что называется каналом. По причинам, которые мы рассмотрим позже в разделе «Каналы» на странице 64, это предполагает, что CalculatePi будет иметь по крайней мере
одну горутину и что нам не следует беспокоиться о создании своей собственной.
Эти изменения затем имеют последствия для производительности, которые необходимо
учесть, и мы возвращаемся к проблеме баланса ясности и производительности.

Ясность важна, потому что мы хотим сделать так, чтобы люди, работающие с этим кодом в будущем, поступали правильно,
а производительность важна по очевидным причинам. Эти два понятия не являются взаимоисключающими, но их трудно смешивать.
Теперь рассмотрим эти трудности в общении и попытаемся масштабировать их до проектов размером с команду.

Ого, это проблема...

Хорошей новостью является то, что Go добился прогресса в упрощении решения подобных проблем. Сам язык способствует читаемости и простоте. То, как он поощряет написание вашего параллельного кода, поощряет корректность, компонуемость и масштабируемость. Фактически, то, как Go обрабатывает параллелизм, может помочь более четко выразить проблемные области! Давайте рассмотрим, почему это так.

### Простое под видом сложного

До сих пор я нарисовал довольно мрачную картину. Параллелизм, безусловно, является сложной областью в компьютерной науке, но я хочу оставить вас с надеждой: эти проблемы не являются неразрешимыми, и с примитивами параллелизма Go вы можете более безопасно и ясно выразить
ваши параллельные алгоритмы. Трудности времени выполнения и коммуникации, которые мы обсудили, никоим образом не решены Go, но они были значительно упрощены. В следующей главе мы узнаем, как был достигнут этот прогресс.

Здесь давайте потратим немного времени на изучение идеи о том, что примитивы параллелизма Go могут
фактически упростить моделирование проблемных областей и более
ясно выразить алгоритмы.

Среда выполнения Go выполняет большую часть тяжелой работы и обеспечивает основу для большинства
прелестей параллелизма Go. Мы отложим обсуждение того, как все это работает, до главы 6, а здесь обсудим, как все это облегчает вам жизнь.

Сначала обсудим параллельный сборщик мусора Go с низкой задержкой. Среди разработчиков часто возникают споры о том,
хорошо ли иметь сборщики мусора в языке. Критики предполагают, что сборщики мусора мешают работе в любой проблемной области,
требующей производительности в реальном времени или детерминированного профиля производительности, —
что приостановка всех действий в программе для очистки мусора просто неприемлема.

Хотя в этом есть некоторая заслуга, отличная работа, проделанная над сборщиком мусора Go,
резко сократила аудиторию, которой нужно беспокоиться о мелочах работы сборщика мусора Go. Начиная с версии Go 1.8, паузы при сборке мусора обычно составляют от 10 до 100 микросекунд!

Как это вам помогает? Управление памятью может быть еще одной сложной проблемой
в области компьютерных наук, и в сочетании с параллелизмом может стать
чрезвычайно сложно писать правильный код. Если вы относитесь к большинству разработчиков,
которым не нужно беспокоиться о паузах длительностью всего 10 микросекунд, Go значительно облегчил использование параллелизма в вашей программе, не заставляя вас управлять памятью, не говоря уже о параллельных процессах.

Среда выполнения Go также автоматически обрабатывает мультиплексирование параллельных операций в
потоки операционной системы. Это сложно, и мы увидим, что именно это означает, в
разделе «Горутины» на странице 37. Чтобы понять, как это
вам помогает, все, что вам нужно знать, это то, что он позволяет вам напрямую отображать параллельные проблемы в параллельные конструкции вместо того, чтобы разбираться с мелочами запуска и управления потоками, а также равномерного отображения логики по доступным потокам.

Например, вы пишете веб-сервер и хотите, чтобы каждое принятое соединение
обрабатывалось одновременно с каждым другим соединением. В некоторых языках, прежде чем ваш
веб-сервер начнет принимать соединения, вам, скорее всего, придется создать коллекцию
потоков, обычно называемую пулом потоков, а затем сопоставить входящие соединения с
потоками. Затем, в каждом созданном вами потоке, вам нужно будет перебрать все соединения в этом потоке, чтобы убедиться, что все они получают некоторое время ЦП. Кроме того, вам придется написать логику обработки соединений так, чтобы ее можно было приостановить, чтобы она
справедливо делилась с другими соединениями.

Ух ты! Напротив, в Go вы бы написали функцию, а затем добавили к ее вызову ключевое слово go. Среда выполнения автоматически обрабатывает все остальное, что мы обсуждали! Когда вы проходите процесс проектирования своей программы, в рамках какой модели, по вашему мнению, вы, скорее всего, достигнете параллелизма? Какая, по вашему мнению, скорее всего, окажется правильной?
Примитивы параллелизма Go также упрощают составление более крупных задач. Как мы увидим
в разделе «Каналы», примитив канала Go обеспечивает компонуемый,
безопасный для параллелизма способ взаимодействия между параллельными процессами.

Я умолчал о большинстве деталей того, как все это работает, но я хотел дать
вам некоторое представление о том, как Go предлагает вам использовать параллелизм в вашей программе, чтобы помочь
вам решать ваши проблемы понятным и производительным способом. В следующей главе мы обсудим философию параллелизма и то, почему Go так много правильного. Если вы хотите
перейти к коду, вы можете перейти к Главе 3.

---

# Глава 2
# Моделирование вашего кода: коммуникация. Последовательные процессы

## Разница между конкурентностью и параллелизмом

Тот факт, что конкурентность отличается от параллелизма, часто упускается из виду или неправильно понимается. В разговорах между многими разработчиками эти два термина часто используются взаимозаменяемо, чтобы обозначить «что-то, что выполняется одновременно с чем-то другим».
Иногда использование слова «параллельный» в этом контексте является правильным, но обычно, если разработчики обсуждают код, им действительно следует использовать слово «конкурентный».

Причина для различения выходит далеко за рамки педантизма. Разница между конкурентностью и параллелизмом оказывается очень мощной абстракцией при моделировании
вашего кода, и Go в полной мере использует это преимущество. Давайте рассмотрим, чем отличаются эти две концепции, чтобы мы могли понять силу этой абстракции. Начнем с очень простого утверждения:

Конкурентность — это свойство кода; параллелизм — это свойство работающей программы.

Это своего рода интересное различие. Разве мы обычно не думаем об этих двух
вещах одинаково? Мы пишем наш код так, чтобы он выполнялся параллельно. Верно?

Что ж, давайте подумаем об этом секунду. Если я пишу свой код с намерением, чтобы два
куска программы выполнялись параллельно, есть ли у меня гарантия, что это действительно
произойдет параллельно, когда программа будет запущена? Что произойдет, если я запущу код на машине с
только одним ядром? Некоторые из вас могут подумать: он будет выполняться параллельно, но это не так!
Кажется, что части нашей программы работают параллельно, но на самом деле они
выполняются последовательно быстрее, чем можно различить. Контекст ЦП
переключается, чтобы разделить время между различными программами, и на достаточно грубой гранулярности времени, задачи, по-видимому, выполняются параллельно. Если бы мы запустили тот же
двоичный файл на машине с двумя ядрами, фрагменты программы могли бы фактически выполняться
параллельно.

Это раскрывает несколько интересных и важных вещей. Во-первых, мы не пишем
параллельный код, только конкурентный код, который, как мы надеемся, будет выполняться параллельно. Еще раз,
параллелизм — это свойство среды выполнения нашей программы, а не кода.

Вторая интересная вещь заключается в том, что мы видим, что может быть, даже не желательно знать, выполняется ли наш конкурентный код на самом деле параллельно. 
Это становится возможным только благодаря слоям абстракции, которые лежат под моделью нашей программы:
примитивам конкурентности, среде выполнения программы, операционной системе, платформе, на которой работает операционная система (в случае гипервизоров, контейнеров и виртуальных
машин) и, в конечном счете, ЦП. Эти абстракции позволяют нам различать параллелизм и конкурентность, и в конечном итоге дают нам силу и гибкость для самовыражения.
Мы вернемся к этому.

Третья и последняя интересная вещь заключается в том, что параллелизм является функцией времени или контекста. Помните, в разделе «Атомарность» мы обсуждали концепцию контекста?
Там контекст определялся как границы, по которым операция считалась
атомарной. Здесь он определяется как границы, по которым две или более операций можно было
считать параллельными.

Например, если бы наш контекст был промежутком в пять секунд, и мы запустили две операции,
каждая из которых выполнялась по секунде, мы бы считали, что операции выполнялись параллельно. Если бы наш контекст длился одну секунду, мы бы считали, что операции выполнялись
последовательно.

Возможно, нам не очень поможет переопределение нашего контекста в терминах временных срезов, но помните, что контекст не ограничен временем. Мы можем определить контекст как
процесс, в котором работает наша программа, поток ее операционной системы или ее машина. Это
важно, потому что определяемый вами контекст тесно связан с концепцией конкурентности и корректности. Так же, как атомарные операции можно считать атомарными в зависимости от определяемого вами контекста, параллельные операции являются корректными в зависимости от определяемого вами контекста. Все это относительно.


Это немного абстрактно, поэтому давайте рассмотрим пример. Допустим, что контекст, который мы обсуждаем, — это
ваш компьютер. Оставив в стороне теоретическую физику, мы можем обоснованно ожидать, что процесс,
выполняющийся на моей машине, не повлияет на логику процесса на вашей машине.
Если мы оба запустим процесс калькулятора и начнем выполнять простую арифметику,
выполняемые мной вычисления не должны влиять на вычисления, выполняемые вами.
Это глупый пример, но если мы разберем его, то увидим все детали в игре: наши машины
являются контекстом, а процессы — параллельными операциями. В этом случае мы решили моделировать наши параллельные операции, думая о мире в терминах отдельных компьютеров, операционных систем и процессов. Эти абстракции позволяют нам уверенно утверждать правильность.

---

### Неужели это действительно глупый пример?

Использование отдельных компьютеров кажется надуманным примером для доказательства, но персональные компьютеры не всегда были столь распространены! До конца 1970-х годов мэйнфреймы
были нормой, и общим контекстом, который разработчики использовали при одновременном обдумывании проблем, был процесс программы.
Теперь, когда многие разработчики работают с распределенными системами, все смещается в другую сторону! Теперь мы начинаем мыслить в терминах гипервизоров, контейнеров и виртуальных машин как наших параллельных контекстов.

---

Мы можем обоснованно ожидать, что один процесс на машине останется незатронутым процессом на другой машине (предполагая, что они не являются частью одной и той же распределенной системы),
но можем ли мы ожидать, что два процесса на одной машине не повлияют на логику друг
друга? Процесс A может перезаписать некоторые файлы, которые читает процесс B, или в незащищенной
ОС процесс A может даже повредить память, которую читает процесс B. Делать это намеренно
— вот как работают многие эксплойты.

Тем не менее, на уровне процесса все остается относительно легко для размышлений. Если мы вернемся к
нашему примеру с калькулятором, все еще разумно ожидать, что два пользователя, запускающие два процесса калькулятора на одной машине, должны обоснованно ожидать, что их операции
будут логически изолированы друг от друга. К счастью, граница процесса и ОС
помогают нам думать об этих проблемах логически. Но мы можем видеть, что разработчик начинает обременяться некоторыми проблемами параллелизма, и эта проблема
только усугубляется. Что, если мы спустимся еще на один уровень ниже, к границе потока ОС? Именно здесь все
проблемы, перечисленные в разделе «Почему сложно параллелизм?» на странице 4,
действительно проявляются: состояния гонки, взаимоблокировки, блокировки в реальном времени и голодание. Если бы у нас был
один процесс калькулятора, в который все пользователи на машине имели представления, было бы
труднее правильно реализовать параллельную логику. Нам пришлось бы начать беспокоиться о
синхронизации доступа к памяти и извлечении правильных результатов для правильного
пользователя.

Происходит то, что по мере того, как мы начинаем спускаться по стеку абстракций, проблема моделирования вещей одновременно становится и более сложной для рассуждений, и более важной. И наоборот, наши абстракции становятся для нас все более и более
важными. Другими словами, чем сложнее правильно реализовать параллелизм, тем
важнее иметь доступ к примитивам параллелизма, которые легко составить. К сожалению, большая часть параллельной логики в нашей отрасли написана на одном из самых высоких уровней абстракции: потоках ОС.

До того, как Go был впервые представлен публике, на этом заканчивалась цепочка абстракций для большинства популярных языков программирования. Если вы хотели написать параллельный код, вы моделировали свою программу в терминах потоков и синхронизировали
доступ к памяти между ними. Если у вас было много вещей, которые вам нужно было моделировать
одновременно, и ваша машина не могла обработать столько потоков, вы создавали
пул потоков и мультиплексировали свои операции в пул потоков.

Go добавил еще одно звено в эту цепочку: goroutine. Кроме того, Go позаимствовал
несколько концепций из работы знаменитого ученого-компьютерщика Тони Хоара и ввел новые примитивы для использования, а именно каналы.
Если продолжить ход рассуждений, которому мы следовали, мы бы предположили, что введение еще одного уровня абстракции ниже потоков ОС принесет с собой больше трудностей, но интересно то, что это не так. На самом деле это упрощает задачу. Это
потому что мы на самом деле не добавили еще один уровень абстракции поверх потоков ОС,
мы вытеснили их.

Потоки, конечно, все еще есть, но мы обнаруживаем, что нам редко приходится думать о нашем
проблемном пространстве с точки зрения потоков ОС. Вместо этого мы моделируем вещи в горутинах и
каналах, а иногда и в общей памяти. Это приводит к некоторым интересным свойствам,
которые мы исследуем в разделе «Как это вам поможет» на странице 29. Но сначала давайте
подробнее рассмотрим, откуда Go взял многие свои идеи — статью, лежащую в основе примитивов параллелизма Go: основополагающую статью Тони Хоара «Общение последовательных процессов».

## Что такое CSP?
Когда обсуждают Go, вы часто слышите, как люди бросаются аббревиатурой CSP.
Часто на одном дыхании ее превозносят как причину успеха Go или панацею для параллельного программирования. Этого достаточно, чтобы люди, которые не знают, что такое CSP,
начали думать, что компьютерная наука открыла какую-то новую технику, которая волшебным образом делает программирование параллельных программ таким же простым, как написание процедурных.

Хотя CSP действительно упрощает вещи и делает программы более надежными, к сожалению, это
не чудо. Так что же это? Что всех так взволновало?

CSP означает «Communicating Sequential Processes» («Взаимодействующие последовательные процессы»), что является одновременно техникой и
названием статьи, в которой она была представлена. В 1978 году Чарльз Энтони Ричард Хоар
опубликовал статью в Association for Computing Machinery (более
популярно называемой ACM). В этой статье Хоар предполагает, что ввод и вывод — это два упускаемых из виду примитива программирования, особенно в параллельном коде. В то время, когда Хоар написал эту статью, исследования по структурированию программ все еще велись, но большая часть этих усилий была направлена ​​на методы последовательного кода: обсуждалось использование оператора goto, и объектно-ориентированная парадигма начала принимать главенствующее место. Параллельные операции не были предметом особого внимания. Хоар решил исправить это, и так родилась его статья и CSP.

В статье 1978 года CSP был всего лишь простым языком программирования, созданным исключительно
для демонстрации мощи передачи последовательных процессов; на самом деле, он даже
говорит в статье:

Таким образом, концепции и обозначения, введенные в этой статье, не
должны рассматриваться как
подходящие для использования в качестве языка программирования, как для абстрактного, так и для конкретного программирования.

Хоар был глубоко обеспокоен тем, что методы, которые он представлял,
ничего не сделали для дальнейшего изучения корректности программ, и что эти методы могут быть неэффективны в реальном языке, основанном на его собственном. В течение следующих шести лет идея CSP
была уточнена в формальное представление того, что называется исчислением процессов, в
попытке взять идеи передачи последовательных процессов и фактически начать
рассуждать о корректности программы. Исчисление процессов — это способ математического моделирования
конкурентных систем, а также предоставляет алгебраические законы для выполнения преобразований в
этих системах для анализа их различных свойств, например, эффективности и корректности.

Хотя исчисление процессов — интересная тема сама по себе, оно выходит за рамки
этой книги. И поскольку исходная статья о CSP и язык, который
развился из нее, в значительной степени послужили источником вдохновения для модели параллелизма Go, именно на них
мы сосредоточимся.

Чтобы поддержать его утверждение о том, что входы и выходы необходимо считать примитивами языка, язык программирования CSP Хоара содержал примитивы для правильного моделирования ввода
и вывода, или связи, между процессами (отсюда и название статьи). Хоар применил термин «процессы» к любой инкапсулированной части
логики, которая требовала ввода для работы и производила вывод, который потребляли бы другие процессы. Хоар, вероятно, мог бы использовать слово «функция», если бы не спор
о том, как структурировать программы, происходящий в сообществе, когда он писал свою статью.
Для связи между процессами Хоар создал команды ввода и вывода: ! для отправки ввода в процесс и ? для чтения вывода из процесса.
Каждая команда должна была указывать либо выходную переменную (в случае чтения переменной из процесса), либо место назначения (в случае отправки ввода в процесс).

Иногда эти два слова относились к одному и тому же, и в этом случае два процесса
считались бы соответствующими. Другими словами, вывод одного процесса
попадал бы непосредственно на ввод другого процесса. В таблице 2-1 показано несколько примеров из
статьи.

![img.png](img/2-1.png)

Сходство с каналами Go очевидно. Обратите внимание, как в последнем примере
выходные данные с запада были отправлены в переменную c, а входные данные с востока были получены из той же
переменной. Эти два процесса соответствуют. В первой статье Хоара по CSP процессы могли общаться только через именованные источники и пункты назначения. Он признал, что это вызовет проблемы со встраиванием кода в качестве библиотеки, поскольку потребители
кода должны будут знать имена входов и выходов. Он небрежно упомянул возможность регистрации того, что он назвал «именами портов», в которых имена
могут быть объявлены в заголовке параллельной команды, что мы, вероятно, распознаем как именованные параметры и именованные возвращаемые значения. Язык также использовал так называемую защищенную команду, которую Эдгар Дейкстра
ввел в предыдущей статье, написанной в 1974 году, «Защищенные команды, неопределенность и формальный вывод программ». Защищенная команда — это просто оператор
с левой и правой частью, разделенный знаком →. Левая часть служила условным выражением или защитой для правой части, поскольку если левая часть была ложной или, в случае
команды, возвращала ложное значение или завершалась, правая часть никогда не выполнялась.

Объединение их с командами ввода-вывода Хоара заложило основу для коммуникационных процессов Хоара и, таким образом, каналов Go.
Используя эти примитивы, Хоар рассмотрел несколько примеров и продемонстрировал,
как язык с первоклассной поддержкой моделирования коммуникации упрощает решение
проблем и делает его более понятным. Некоторые из используемых им обозначений немного
кратки (программисты Perl, вероятно, не согласятся!), но проблемы, которые он представляет,
имеют необычайно ясные решения. Аналогичные решения в Go немного длиннее, но также
несут в себе эту ясность.

История расценила предложение Хоара как правильное; однако интересно отметить,
что до того, как был выпущен Go, лишь немногие языки действительно внесли поддержку этих
примитивов в язык. Большинство популярных языков отдают предпочтение совместному использованию и синхронизации доступа к памяти в стиле передачи сообщений CSP. Есть исключения,
но, к сожалению, они ограничены языками, которые не получили широкого распространения. Go
один из первых языков, включивших принципы CSP в свое ядро ​​и принесших
этот стиль параллельного программирования в массы. Его успех побудил другие языки также попытаться добавить эти примитивы.

Синхронизация доступа к памяти сама по себе не плоха. Позже в этой главе (в разделе «Философия параллелизма Go» на стр. 31) мы увидим, что иногда совместное использование памяти
уместно в определенных ситуациях, даже в Go. Однако модель общей памяти может
быть сложной для правильного использования, особенно в больших или сложных программах. Именно по этой причине параллелизм считается одной из сильных сторон Go: он
был построен с самого начала с учетом принципов CSP, поэтому его легко читать, писать и рассуждать.

## Как это нам поможет?

Вы можете посчитать все это увлекательным или нет, но есть вероятность, что если вы читаете
эту книгу, у вас есть проблемы, которые нужно решить, и вы задаетесь вопросом, почему все это имеет значение.
Что делает Go так по-другому, что отличает его от других популярных языков,
когда дело доходит до параллелизма?

Как мы обсуждали в разделе «Разница между конкурентностью и параллелизмом» на стр. 23 для моделирования параллельных задач, языки обычно заканчивают
свою цепочку абстракций на уровне потока ОС и синхронизации доступа к памяти. Go идет другим путем и заменяет это концепцией горутин
и каналов. Если бы мы провели сравнение между концепциями в двух способах абстрагирования параллельного кода, мы, вероятно, сравнили бы горутину с потоком, а канал с мьютексом (эти примитивы имеют лишь мимолетное сходство, но, надеюсь, сравнение поможет вам сориентироваться). Что делают для нас эти разные абстракции?

Горутины освобождают нас от необходимости думать о нашем проблемном пространстве с точки зрения параллелизма и вместо этого позволяют нам моделировать проблемы ближе к их естественному уровню конкурентности. Хотя мы рассмотрели разницу между параллелизмом и конкурентностью, то, как эта разница влияет на то, как мы моделируем решения, может быть неясно. Давайте перейдем к примеру.

Допустим, мне нужно создать веб-сервер, который обрабатывает запросы на конечной точке. Оставив в стороне фреймворки на мгновение, в языке, который предлагает только абстракцию потоков, я бы, вероятно, размышлял над следующими вопросами:
- Поддерживает ли мой язык потоки естественным образом или мне придется выбирать библиотеку?
- Где должны быть границы ограничения потоков?
- Насколько тяжелы потоки в этой операционной системе?
- Как операционные системы, в которых будет работать моя программа, обрабатывают потоки
по-разному?
- Мне следует создать пул рабочих, чтобы ограничить количество создаваемых мной потоков. Как мне найти оптимальное число?
  
Все это важные вещи для рассмотрения, но ни одна из них напрямую не касается проблемы, которую вы пытаетесь решить. Вас немедленно затянуло в технические детали того, как вы собираетесь решать проблему параллелизма.
Если мы сделаем шаг назад и подумаем о естественной проблеме, мы могли бы сформулировать ее так: отдельные пользователи подключаются к моей конечной точке и открывают сеанс. Сеанс должен
отправить свой запрос и вернуть ответ. В Go мы можем почти напрямую представить естественное состояние этой проблемы в коде: мы создадим горутину для каждого
входящего соединения, отобразим запрос там (потенциально взаимодействуя с другими горутинами для данных/сервисов), а затем вернёмся из функции горутины. То, как мы
естественно думаем о проблеме, напрямую соответствует естественному способу кодирования вещей в
Go. Это достигается обещанием, которое дает нам Go: что горутины легковесны, и нам
обычно не придется беспокоиться о создании одной. Есть подходящие моменты, чтобы рассмотреть, сколько горутинов запущено в вашей системе, но делать это заранее - это, безусловно, преждевременная оптимизация. Сравните это с потоками, где было бы
мудро рассмотреть такие вопросы заранее.

То, что есть фреймворк для языка, который абстрагирует проблемы параллелизма для вас, не означает, что этот естественный способ моделирования параллельных
проблем не имеет значения! Кто-то должен написать фреймворк, и ваш код будет
сидеть поверх любой сложности, с которой пришлось иметь дело автору(ам). То, что сложность скрыта от вас, не означает, что ее нет, а сложность порождает
ошибки. В случае Go язык был разработан вокруг параллелизма, поэтому язык не несовместим с примитивами параллелизма, которые он предоставляет. Это означает меньше
трений и меньше ошибок!

Более естественное отображение в проблемное пространство — это огромное преимущество, но оно также имеет несколько
полезных побочных эффектов. Среда выполнения Go автоматически мультиплексирует горутины в потоки ОС и управляет их планированием для нас. Это означает, что оптимизацию среды выполнения можно выполнять без необходимости изменять то, как мы смоделировали нашу проблему; это классическое разделение интересов. По мере развития параллелизма
среда выполнения Go будет улучшаться, как и производительность вашей программы — все это бесплатно.
Следите за заметками о выпуске Go, и иногда вы увидите такие вещи, как:  
В Go 1.5 порядок планирования горутинов был изменен.

Авторы Go вносят улучшения за кулисами, чтобы сделать вашу программу
быстрее. Такое разделение параллелизма и конкурентности имеет еще одно преимущество: поскольку среда выполнения Go управляет планированием горутин для вас, она может анализировать вещи как горутины, заблокированные в ожидании ввода-вывода, и разумно перераспределяют потоки ОС в горутины, которые не заблокированы. Это также повышает производительность вашего кода. Мы
подробнее обсудим, что делает для вас среда выполнения Go в Главе 6.

Еще одним преимуществом более естественного сопоставления между проблемными пространствами и
кодом Go является вероятное увеличение объема проблемного пространства, смоделированного в конкурентном
образе. Поскольку проблемы, над которыми мы работаем как разработчики, по своей природе
чаще конкурентны, мы, естественно, будем писать конкурентный код на более
тонком уровне детализации, чем, возможно, в других языках; например, если мы вернемся к нашему
примеру с веб-сервером, то теперь у нас будет горутина для каждого пользователя вместо соединений,
мультиплексированных в пул потоков. Этот более тонкий уровень детализации позволяет нашей программе
динамически масштабироваться, когда она работает до возможного уровня параллелизма на хосте программы — закон Амдаля в действии! Это довольно удивительно. И горутины — это только часть головоломки. Другие концепции из CSP, каналы и операторы select, также добавляют ценность.
Например, каналы по своей сути компонуются с другими каналами. Это упрощает написание больших систем, поскольку вы можете координировать ввод из нескольких подсистем, легко компонуя вывод. Вы можете объединять входные каналы
с тайм-аутами, отменами или сообщениями для других подсистем. Координация мьютексов
— гораздо более сложная задача.

Оператор select является дополнением к каналам Go и позволяет выполнять все
сложные части компоновки каналов. Операторы select позволяют вам эффективно ожидать
событий, выбирать сообщение из конкурирующих каналов унифицированным случайным образом, продолжать, если нет ожидающих сообщений, и многое другое.
Этот замечательный гобелен примитивов, вдохновленный CSP, и среда выполнения, которая его поддерживает,
являются тем, что питает Go. Оставшуюся часть книги мы посвятим изучению того, как работают эти вещи, почему и как мы можем использовать их для написания потрясающего кода.

## Философия конкурентности в Go.

CSP был и остается большой частью того, вокруг чего был разработан Go; однако Go также поддерживает более традиционные средства написания параллельного кода с помощью синхронизации доступа к памяти и примитивов, которые следуют этой технике. Структуры и методы в пакетах sync и других позволяют вам выполнять блокировки, создавать пулы ресурсов, вытеснять горутины и многое другое.

Эта возможность выбора между примитивами CSP и синхронизацией доступа к памяти
отлично подходит для вас, поскольку она дает вам немного больше контроля над тем, какой стиль параллельного кода вы выберете для решения проблем, но это также может немного сбивать с толку. У новичков в языке часто складывается впечатление, что стиль параллелизма CSP считается единственным способом писать параллельный код в Go. Например, в
документации по пакету sync говорится:
- Пакет sync предоставляет базовые примитивы синхронизации, такие как блокировки взаимного исключения. За исключением типов Once и WaitGroup, большинство из них предназначены для использования низкоуровневыми библиотечными процедурами. Синхронизация более высокого уровня лучше осуществляется через каналы и
коммуникации.

В FAQ по языку говорится:
- Что касается мьютексов, пакет sync реализует их, но мы надеемся, что стиль программирования Go
побудит людей попробовать более высокоуровневые методы. В частности, рассмотрите возможность структурирования вашей программы таким образом, чтобы только одна горутина в каждый момент времени отвечала за определенный фрагмент данных.
- Не общайтесь через общую память. Вместо этого делитесь памятью через общение.

Существует также множество статей, лекций и интервью, в которых различные члены
основной команды Go поддерживают стиль CSP вместо примитивов, таких как sync.Mutex.

Поэтому вполне понятно, почему команда Go решила
выставить примитивы синхронизации доступа к памяти вообще. Что может быть еще более
запутанным, так это то, что вы увидите примитивы синхронизации, которые широко распространены, увидите, как люди жалуются на чрезмерное использование каналов, а также услышите, как некоторые члены команды Go утверждают, что их можно использовать. Вот цитата из Go Wiki по этому поводу:
- Один из девизов Go — «Делитесь памятью, общаясь, не общайтесь, разделяя память».
- Тем не менее, Go предоставляет традиционные механизмы блокировки в пакете синхронизации. Большинство
проблем блокировки можно решить с помощью каналов или традиционных блокировок.
- Так что же вам следует использовать?
- Используйте то, что наиболее выразительно и/или наиболее просто.
Это хороший совет, и это руководство вы часто видите при работе с Go, но оно
немного расплывчато. Как нам понять, что более выразительно и/или проще?

Какие критерии мы можем использовать? К счастью, есть некоторые ориентиры, которые мы можем использовать, чтобы помочь
нам сделать правильно. Как мы увидим, способ, которым мы можем различать, в основном исходит из того,
где мы пытаемся управлять нашим параллелизмом: внутри в узкой области или снаружи по всей нашей системе. Рисунок 2-1 перечисляет эти ориентиры в дереве решений.

![img.png](img/figure2-1.png)

Давайте рассмотрим эти точки принятия решений по одной:
- Вы пытаетесь передать право собственности на данные?  

Если у вас есть фрагмент кода, который производит результат, и вы хотите поделиться этим результатом с
другим фрагментом кода, то на самом деле вы передаете право собственности на эти
данные. Если вы знакомы с концепцией владения памятью в языках, которые
не поддерживают сборку мусора, то это та же идея: у данных есть владелец, и
один из способов сделать параллельные программы безопасными — гарантировать, что только один параллельный контекст владеет данными одновременно. Каналы помогают нам передать эту концепцию,
кодируя это намерение в тип канала.

Одним из больших преимуществ этого является то, что вы можете создавать буферизованные каналы для реализации
дешевой очереди в памяти и, таким образом, отделить вашего производителя от потребителя.
Другое заключается в том, что, используя каналы, вы неявно делаете свой параллельный код
компонуемым с другим параллельным кодом.

- Вы пытаетесь защитить внутреннее состояние структуры?  

Это отличный кандидат на примитивы синхронизации доступа к памяти и
достаточно сильный индикатор того, что вам не следует использовать каналы. Используя примитивы синхронизации доступа к памяти, вы можете скрыть детали реализации блокировки
вашей критической секции от ваших вызывающих. Вот небольшой пример типа, который является потокобезопасным, но не раскрывает эту сложность для своих вызывающих:

```go
type Counter struct {
   mu sync.Mutex
   value int
}
func (c *Counter) Increment() {
   c.mu.Lock()
   defer c.mu.Unlock()
   c.value++
}
```

Если вы помните концепцию атомарности, то можно сказать, что мы здесь
определили область атомарности для типа Counter. Вызовы Increment можно
считаь атомарными.

Помните, что ключевое слово здесь — «внутренний». Если вы обнаруживаете, что раскрываете блокировки
за пределами типа, это должно вызвать тревогу. Постарайтесь ограничить блокировки
небольшой лексической областью действия.

- Вы пытаетесь координировать несколько фрагментов логики?

Помните, что каналы по своей сути более компонуемы, чем примитивы синхронизации доступа к памяти. Наличие блокировок, разбросанных по всему объектному графу,
звучит как кошмар, но наличие каналов повсюду ожидается и
поощряется! Я могу компоновать каналы, но я не могу легко компоновать блокировки или методы,
которые возвращают значения.

Вы обнаружите, что вам будет гораздо проще контролировать возникающую сложность,
возникающую в вашем программном обеспечении, если вы используете каналы из-за оператора select в Go и их
способности служить очередями и безопасно передаваться. Если вы обнаружите, что вам трудно понять, как работает ваш параллельный код, почему возникает взаимоблокировка или гонка, и вы используете примитивы, это, вероятно, хороший показатель того, что вам следует переключиться на каналы.
- Это раздел, критически важный для производительности?

Это совершенно не означает: «Я хочу, чтобы моя программа была производительной, поэтому я
буду использовать только мьютексы». Скорее, если у вас есть раздел вашей программы, который вы
пропрофилировали, и он оказывается основным узким местом, которое на порядки медленнее остальной части программы, использование примитивов синхронизации доступа к памяти
может помочь этому критическому разделу работать под нагрузкой. Это связано с тем, что
каналы используют синхронизацию доступа к памяти для работы, поэтому они могут быть только
медленнее. Однако, прежде чем мы даже рассмотрим это, раздел, критически важный для производительности,
может намекать, что нам нужно реструктурировать нашу программу.

Надеюсь, это прояснит, следует ли использовать параллелизм в стиле CSP или синхронизацию доступа к памяти. Существуют другие шаблоны и практики, которые полезны в языках, использующих поток ОС как средство абстрагирования параллелизма. Например, часто возникают такие вещи, как пулы потоков. Поскольку большинство этих абстракций нацелены на сильные и слабые стороны потоков ОС, хорошее практическое правило при работе с Go — отказаться от этих шаблонов. Это не значит, что они бесполезны
вообще, но варианты использования, безусловно, гораздо более ограничены в Go. Придерживайтесь моделирования
проблемного пространства с помощью горутин, используйте их для представления параллельных частей
вашего рабочего процесса и не бойтесь быть либеральными при их запуске. Вам гораздо
вероятнее придется реструктурировать свою программу, чем начать сталкиваться с
верхним пределом того, сколько горутин может поддерживать ваше оборудование.

Философию Go в отношении параллелизма можно резюмировать следующим образом: стремитесь к простоте, используйте
каналы, когда это возможно, и относитесь к горутинам как к бесплатному ресурсу.
