# Глава 1. Введение в конкурентность

---

Конкурентность — интересное понятие, потому что в нашей сфере оно означает разное для разных людей. Помимо слова «конкурентность», вы могли слышать термины «асинхронность», «параллелизм» или «многопоточность». Некоторые считают их синонимами, другие же строго разграничивают их значения. Поскольку мы посвятим конкурентности целую книгу, полезно сначала разобраться, что именно мы подразумеваем под этим термином.

В главе 2 мы подробнее рассмотрим философию конкурентности, но пока примем практическое определение, которое станет основой для нашего понимания.

Когда большинство людей говорят о «конкурентности», они обычно имеют в виду процесс, выполняемый одновременно с одним или несколькими другими процессами. При этом подразумевается, что все эти процессы продвигаются примерно в одно и то же время. Простой аналогией могут быть люди: прямо сейчас вы читаете это предложение, а другие в мире одновременно живут своей жизнью. Они существуют конкурентно по отношению к вам.

Конкурентность — обширная тема в компьютерных науках, и из этого определения вытекает множество аспектов: теория, моделирование конкурентности, корректность логики, практические проблемы и даже теоретическая физика! В книге мы затронем некоторые смежные темы, но сосредоточимся в основном на практических вопросах, связанных с конкурентностью в контексте Go. А именно: как Go моделирует конкурентность, какие проблемы возникают из этой модели и как можно комбинировать её примитивы для решения задач.

В этой главе мы в общих чертах рассмотрим, почему конкурентность стала столь важной темой в компьютерных науках, почему она сложна и требует тщательного изучения, а главное — как, несмотря на эти трудности, Go позволяет делать программы понятнее и быстрее благодаря своим примитивам конкурентности.

Как и в любом исследовании, начнём с истории. Давайте сначала разберёмся, почему конкурентность приобрела такое важное значение.

## Закон Мура, веб-масштабируемость и проблемы, в которых мы оказались

В 1965 году Гордон Мур опубликовал трёхстраничную статью, в которой предсказал консолидацию рынка электроники вокруг интегральных схем и удвоение количества компонентов в схемах каждый год на протяжении как минимум десятилетия. В 1975 году он скорректировал своё предсказание, утверждая, что количество компонентов на интегральной схеме будет удваиваться каждые два года. Это предсказание оставалось верным вплоть до недавнего времени — примерно до 2012 года.

Несколько компаний предвидели замедление темпов роста, предусмотренного законом Мура, и начали исследовать альтернативные способы повышения вычислительной мощности. Как говорится, необходимость — мать изобретений, и именно таким образом были созданы многоядерные процессоры.

Это выглядело как умное решение проблемы ограничения закона Мура, однако вскоре компьютерные учёные столкнулись с ограничениями другого закона: закона Амдала, названного в честь архитектора компьютеров Джина Амдала.

Закон Амдала описывает потенциальный прирост производительности при параллельном решении задачи. Проще говоря, он утверждает, что этот прирост ограничен скоростью работы программы, которую нельзя распараллелить

### Пример 1: Программа с графическим интерфейсом

Представьте приложение с GUI: пользователь видит интерфейс, нажимает кнопки, и что-то происходит. Здесь критическая часть конвейера — взаимодействие с человеком — строго последовательна. Сколько бы ядер вы ни добавили, программа всё равно будет ограничена скоростью реакции пользователя.

### Пример 2: Вычисление цифр числа π

Благодаря spigot-алгоритмам, эта задача относится к «заведомо параллельным» (англ. embarrassingly parallel). Это технический термин (да, звучит странно), означающий, что задачу легко разбить на независимые подзадачи. Здесь добавление ядер значительно ускорит вычисления, а сложность сместится к агрегации результатов.

Закон Амдала помогает понять разницу между такими задачами и решить, стоит ли распараллеливание усилий.

Для заведомо параллельных задач рекомендуется горизонтальное масштабирование: запуск копий программы на дополнительных CPU или машинах для сокращения времени выполнения. Такие задачи идеально подходят для этого подхода, так как их легко разбить на части для распределённой обработки.

В начале 2000-х горизонтальное масштабирование упростилось благодаря облачным вычислениям. Хотя термин появился ещё в 1970-х, именно тогда он стал мейнстримом. Облака предложили новый масштаб: вместо ручного управления серверами разработчики получили доступ к пулам ресурсов, которые динамически выделялись под задачи. Машины стали «эфемерными», настраиваемыми под конкретные нагрузки и задачи, и часто размещались в дата-центрах сторонних компаний.

Это породило новую парадигму мышления: теперь у разработчиков был дешёвый доступ к огромным вычислительным мощностям. Решения могли охватывать сотни машин и географических регионов, делая технологии, ранее доступные только гигантам вроде Google, достоянием всех.

Однако облака принесли и проблемы:

- Оркестрация ресурсов
- Обмен данными между инстансами
- Агрегация и хранение результатов.

Но сложнее всего оказалось правильно смоделировать конкурентный код. Распределённость системы усугубила типичные проблемы параллелизма. Успешное решение этих задач породило новый стандарт — web scale.
Web-scale-программы — это, среди прочего, заведомо параллельные системы, способные обрабатывать сотни тысяч запросов в секунду за счёт добавления инстансов. Это обеспечило:

- Бесшовные обновления,
- Гибкую масштабируемость,
- Геораспределённость.

Но также добавило сложностей в понимании кода и отказоустойчивости.

И вот мы оказываемся в этом мире — мире многоядерных процессоров, облачных вычислений, веб-масштабируемости и задач, которые могут быть как распараллелены, так и нет. Современный разработчик зачастую чувствует себя несколько подавленным. Эстафетная палочка передана нам, и теперь именно мы должны решать задачи в рамках тех аппаратных ограничений, которые имеем.

В 2005 году Херб Саттер написал знаковую статью для Dr. Dobb's под названием «Бесплатный обед закончен: фундаментальный поворот к конкурентности в программном обеспечении». Название оказалось пророческим. В конце статьи Саттер делает важное заявление:

«Нам отчаянно необходима более высокоуровневая модель конкурентности, чем та, что предлагают современные языки программирования»
Чтобы понять, почему Саттер использует такие сильные выражения, нужно разобраться, почему конкурентность так сложно реализовать правильно.

## Почему конкурентность это сложно?

Работа с конкурентным кодом печально известна своей сложностью. Обычно требуется несколько итераций, чтобы заставить его работать как задумано. Но даже тогда нередки случаи, когда ошибки остаются незамеченными годами, пока изменение условий (возросшая нагрузка на диск, больше пользователей в системе и т.д.) не вызовет проявление ранее скрытого бага. Кстати, для примеров кода в этой книге я привлек максимальное количество рецензентов, чтобы минимизировать такие проблемы.

К счастью, все разработчики сталкиваются с одинаковыми проблемами при работе с конкурентным кодом. Благодаря этому знатоки computer science смогли классифицировать типичные проблемы, что позволяет нам обсуждать причины их возникновения и способы решения.

Давайте рассмотрим основные проблемы, которые делают работу с конкурентным кодом одновременно сложной и интересной:

## Состояние гонки (Race Conditions)

Состояние гонки возникает, когда две или более операций должны выполняться в строго определённом порядке, но программа не гарантирует соблюдение этого порядка выполнения.

Чаще всего это проявляется в так называемой "гонке данных" (data race), когда одна конкурентная операция пытается прочитать переменную, в то время как в какой-то неопределённый момент времени другая конкурентная операция пытается записать значение в эту же переменную.

Приведём простой пример:
```go
var data int
go func() {
    data++
}()
if data == 0 {
    fmt.Printf("the value is %v.\n", data)
}
```

В Go для параллельного выполнения функций используется ключевое слово go, которое создает так называемую горутину (подробнее в разделе "Горутины").

Рассмотрим пример, где строки 3 и 5 пытаются получить доступ к переменной data без гарантии порядка выполнения. Возможные сценарии выполнения:

- Ничего не выводится - строка 3 выполнилась до строки 5
- Выводится "the value is 0" - строки 5-6 выполнились до строки 3
- Выводится "the value is 1" - строка 5 выполнилась до 3, но 3 выполнилась до 6

## Почему возникают гонки данных? (race conditions)

Как вы можете видеть, всего несколько строк неправильного кода могут внести огромную нестабильность
в вашу программу.

В большинстве случаев гонки данных возникают, потому что разработчики думают о
коде последовательно. Они предполагают, что поскольку строка кода находится перед другой,
она будет запущена первой. Они предполагают, что вышеприведенная горутина будет запланирована и выполнена
до того, как переменная data будет прочитана в операторе if.

При написании параллельного кода вам нужно тщательно перебирать возможные
сценарии. Если вы не используете некоторые из методов, которые мы рассмотрим далее в книге,
у вас нет гарантий, что ваш код будет запущен в том порядке, в котором он указан в исходном
коде.

Иногда я нахожу полезным представить, что между вызываемыми операциями проходит большой период.
Представьте, что между вызовом горутины и ее выполнением пройдет час. Как тогда поведет себя оставшаяся часть кода?
А что, если бы между успешным выполнением горутины и достижением программой оператора if
прошел час?
Мне помогает такой подход, потому что для компьютера масштаб может быть
другим, но смысл от этого не теряется.
Но такая мысль приводит разработчика в ловушку разбрасывания sleep по всему коду. Как им кажется, это решает проблемы с параллелизмом. Давайте попробуем это в предыдущей программе:

```go
var data int
go func() { data++ }()
time.Sleep(1*time.Second) // This is bad!
if data == 0 {
    fmt.Printf("the value is %v.\n" data)
}
```

Решили ли мы нашу гонку данных? Нет. На самом деле, все три результата все еще могут возникнуть из этой программы, просто это становится все менее вероятным. Чем дольше мы спим между вызовом нашей горутины и проверкой значения данных, тем ближе наша программа становится к достижению корректности, но эта вероятность асимптотически приближается к логической корректности; она никогда не будет логически корректной.
В дополнение к этому, мы теперь внесли неэффективность в наш алгоритм. Теперь нам нужно спать одну секунду, чтобы повысить вероятность того, что мы не увидим нашу гонку данных. Если бы мы использовали правильные инструменты, нам, возможно, вообще не пришлось бы ждать, или ожидание могло бы составлять всего
микросекунду.
Вывод здесь в том, что вы всегда должны стремиться к логической корректности. 

Внедрение time.Sleep() в ваш код может быть удобным способом отладки параллельных программ, но это не решение.

Состояние гонки — один из самых коварных типов ошибок параллелизма, потому что они
могут не проявляться до тех пор, пока код не будет запущен в производство. Они
обычно вызваны изменением среды, в которой выполняется код, или
беспрецедентным событием. В этих случаях код, кажется, ведет себя правильно,
но на самом деле существует просто очень высокая вероятность того, что операции будут выполнены в
порядке. Рано или поздно программа будет иметь непредвиденные последствия.

## Атомарность

Когда что-то считается атомарным или имеет свойство атомарности, это
означает, что в контексте, в котором оно работает, оно неделимо или непрерываемо.

Так что же это на самом деле означает, и почему это важно знать при работе с
параллельным кодом?

Первое, что очень важно, — это слово «контекст». Что-то может быть атомарным
в одном контексте, но не в другом. Операции, которые являются атомарными в контексте вашего
процесса, могут не быть атомарными в контексте операционной системы; операции, которые являются
атомарными в контексте операционной системы, могут не быть атомарными в контексте вашей
машины; и операции, которые являются атомарными в контексте вашей
машины, могут не быть атомарными в контексте вашего приложения. Другими словами,
атомарность операции может меняться в зависимости от текущей определенной области действия.
Этот факт может работать как за, так и против вас!

Когда вы думаете об атомарности, очень часто первое, что вам нужно сделать, это определить
контекст или область действия, в которой операция будет считаться атомарной. Все
следует из этого.

---
### Интересный факт

В 2006 году игровая компания Blizzard успешно подала в суд на MDY Industries на
6 000 000 долларов США за создание программы под названием «Glider», которая автоматически
играла в их игру World of Warcraft без вмешательства пользователя. Такие типы программ обычно называют «ботами» (сокращение от robots).
В то время в World of Warcraft была античит-программа под названием «Warden», которая
запускалась в любое время, когда вы играли в игру. Помимо прочего, Warden сканировал
память хост-машины и запускал эвристику для поиска программ,
которые, по-видимому, использовались для мошенничества.
Glider успешно избежал этой проверки, воспользовавшись концепцией атомарного
контекста. Warden считал сканирование памяти на машине атомарной операцией, но Glider использовал аппаратные прерывания, чтобы скрыть себя до начала этого сканирования! Сканирование памяти Уорденом было атомарным в контексте процесса, но не в контексте операционной системы.

---

Теперь давайте рассмотрим термины «неделимый» и «непрерываемый». Эти термины означают, что
в контексте, который вы определили, что-то, что является атомарным, произойдет полностью,
без того, чтобы что-либо происходило в этом контексте одновременно. Это все еще труднопроизносимо, поэтому
давайте рассмотрим пример:
```go
i++
```

Это такой простой пример, какой только можно придумать, и тем не менее он легко демонстрирует концепцию атомарности. Он может выглядеть атомарным, но краткий анализ показывает несколько операций:
- Извлечь значение i.
- Увеличить значение i.
- Сохранение значения i.

Хотя каждая из этих операций по отдельности является атомарной, комбинация этих трех может
не быть таковой, в зависимости от вашего контекста. Это раскрывает интересное свойство атомарных операций: их объединение не обязательно приводит к более крупной атомарной операции. Сделать операцию атомарной зависит от того, в каком контексте вы хотите, чтобы она была атомарной. Если ваш контекст — это программа без параллельных процессов, то этот код является
атомарным в этом контексте. Если ваш контекст — это goroutine, которая не раскрывает i
другим goroutine, то этот код является атомарным.

Так почему же нас это волнует? Атомарность важна, потому что если что-то является атомарным, то неявно
оно безопасно в параллельных контекстах. Это позволяет нам составлять логически правильные программы и, как мы увидим позже, может даже служить способом оптимизации параллельных программ.

Большинство операторов не являются атомарными, не говоря уже о функциях, методах и программах.
Если атомарность является ключом к составлению логически правильных программ, а большинство операторов не являются
атомарными, как нам согласовать эти два оператора? Мы углубимся в это позже, но
говоря короче, мы можем форсировать атомарность, используя различные методы. 
Суть данного искусства - определить, какие области вашего кода должны быть атомарными и на каком уровне
детализации. Некоторые из этих проблем мы обсудим в следующем разделе.