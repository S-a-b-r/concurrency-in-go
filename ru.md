# Глава 1. Введение в конкурентность

---

Конкурентность — интересное понятие, потому что в нашей сфере оно означает разное для разных людей. Помимо слова «конкурентность», вы могли слышать термины «асинхронность», «параллелизм» или «многопоточность». Некоторые считают их синонимами, другие же строго разграничивают их значения. Поскольку мы посвятим конкурентности целую книгу, полезно сначала разобраться, что именно мы подразумеваем под этим термином.

В главе 2 мы подробнее рассмотрим философию конкурентности, но пока примем практическое определение, которое станет основой для нашего понимания.

Когда большинство людей говорят о «конкурентности», они обычно имеют в виду процесс, выполняемый одновременно с одним или несколькими другими процессами. При этом подразумевается, что все эти процессы продвигаются примерно в одно и то же время. Простой аналогией могут быть люди: прямо сейчас вы читаете это предложение, а другие в мире одновременно живут своей жизнью. Они существуют конкурентно по отношению к вам.

Конкурентность — обширная тема в компьютерных науках, и из этого определения вытекает множество аспектов: теория, моделирование конкурентности, корректность логики, практические проблемы и даже теоретическая физика! В книге мы затронем некоторые смежные темы, но сосредоточимся в основном на практических вопросах, связанных с конкурентностью в контексте Go. А именно: как Go моделирует конкурентность, какие проблемы возникают из этой модели и как можно комбинировать её примитивы для решения задач.

В этой главе мы в общих чертах рассмотрим, почему конкурентность стала столь важной темой в компьютерных науках, почему она сложна и требует тщательного изучения, а главное — как, несмотря на эти трудности, Go позволяет делать программы понятнее и быстрее благодаря своим примитивам конкурентности.

Как и в любом исследовании, начнём с истории. Давайте сначала разберёмся, почему конкурентность приобрела такое важное значение.

## Закон Мура, веб-масштабируемость и проблемы, в которых мы оказались

В 1965 году Гордон Мур опубликовал трёхстраничную статью, в которой предсказал консолидацию рынка электроники вокруг интегральных схем и удвоение количества компонентов в схемах каждый год на протяжении как минимум десятилетия. В 1975 году он скорректировал своё предсказание, утверждая, что количество компонентов на интегральной схеме будет удваиваться каждые два года. Это предсказание оставалось верным вплоть до недавнего времени — примерно до 2012 года.

Несколько компаний предвидели замедление темпов роста, предусмотренного законом Мура, и начали исследовать альтернативные способы повышения вычислительной мощности. Как говорится, необходимость — мать изобретений, и именно таким образом были созданы многоядерные процессоры.

Это выглядело как умное решение проблемы ограничения закона Мура, однако вскоре компьютерные учёные столкнулись с ограничениями другого закона: закона Амдала, названного в честь архитектора компьютеров Джина Амдала.

Закон Амдала описывает потенциальный прирост производительности при параллельном решении задачи. Проще говоря, он утверждает, что этот прирост ограничен скоростью работы программы, которую нельзя распараллелить

### Пример 1: Программа с графическим интерфейсом

Представьте приложение с GUI: пользователь видит интерфейс, нажимает кнопки, и что-то происходит. Здесь критическая часть конвейера — взаимодействие с человеком — строго последовательна. Сколько бы ядер вы ни добавили, программа всё равно будет ограничена скоростью реакции пользователя.

### Пример 2: Вычисление цифр числа π

Благодаря spigot-алгоритмам, эта задача относится к «заведомо параллельным» (англ. embarrassingly parallel). Это технический термин (да, звучит странно), означающий, что задачу легко разбить на независимые подзадачи. Здесь добавление ядер значительно ускорит вычисления, а сложность сместится к агрегации результатов.

Закон Амдала помогает понять разницу между такими задачами и решить, стоит ли распараллеливание усилий.

Для заведомо параллельных задач рекомендуется горизонтальное масштабирование: запуск копий программы на дополнительных CPU или машинах для сокращения времени выполнения. Такие задачи идеально подходят для этого подхода, так как их легко разбить на части для распределённой обработки.

В начале 2000-х горизонтальное масштабирование упростилось благодаря облачным вычислениям. Хотя термин появился ещё в 1970-х, именно тогда он стал мейнстримом. Облака предложили новый масштаб: вместо ручного управления серверами разработчики получили доступ к пулам ресурсов, которые динамически выделялись под задачи. Машины стали «эфемерными», настраиваемыми под конкретные нагрузки и задачи, и часто размещались в дата-центрах сторонних компаний.

Это породило новую парадигму мышления: теперь у разработчиков был дешёвый доступ к огромным вычислительным мощностям. Решения могли охватывать сотни машин и географических регионов, делая технологии, ранее доступные только гигантам вроде Google, достоянием всех.

Однако облака принесли и проблемы:

- Оркестрация ресурсов
- Обмен данными между инстансами
- Агрегация и хранение результатов.

Но сложнее всего оказалось правильно смоделировать конкурентный код. Распределённость системы усугубила типичные проблемы параллелизма. Успешное решение этих задач породило новый стандарт — web scale.
Web-scale-программы — это, среди прочего, заведомо параллельные системы, способные обрабатывать сотни тысяч запросов в секунду за счёт добавления инстансов. Это обеспечило:

- Бесшовные обновления,
- Гибкую масштабируемость,
- Геораспределённость.

Но также добавило сложностей в понимании кода и отказоустойчивости.

И вот мы оказываемся в этом мире — мире многоядерных процессоров, облачных вычислений, веб-масштабируемости и задач, которые могут быть как распараллелены, так и нет. Современный разработчик зачастую чувствует себя несколько подавленным. Эстафетная палочка передана нам, и теперь именно мы должны решать задачи в рамках тех аппаратных ограничений, которые имеем.

В 2005 году Херб Саттер написал знаковую статью для Dr. Dobb's под названием «Бесплатный обед закончен: фундаментальный поворот к конкурентности в программном обеспечении». Название оказалось пророческим. В конце статьи Саттер делает важное заявление:

«Нам отчаянно необходима более высокоуровневая модель конкурентности, чем та, что предлагают современные языки программирования»
Чтобы понять, почему Саттер использует такие сильные выражения, нужно разобраться, почему конкурентность так сложно реализовать правильно.

## Почему конкурентность это сложно?

Работа с конкурентным кодом печально известна своей сложностью. Обычно требуется несколько итераций, чтобы заставить его работать как задумано. Но даже тогда нередки случаи, когда ошибки остаются незамеченными годами, пока изменение условий (возросшая нагрузка на диск, больше пользователей в системе и т.д.) не вызовет проявление ранее скрытого бага. Кстати, для примеров кода в этой книге я привлек максимальное количество рецензентов, чтобы минимизировать такие проблемы.

К счастью, все разработчики сталкиваются с одинаковыми проблемами при работе с конкурентным кодом. Благодаря этому знатоки computer science смогли классифицировать типичные проблемы, что позволяет нам обсуждать причины их возникновения и способы решения.

Давайте рассмотрим основные проблемы, которые делают работу с конкурентным кодом одновременно сложной и интересной:

## Состояние гонки (Race Conditions)

Состояние гонки возникает, когда две или более операций должны выполняться в строго определённом порядке, но программа не гарантирует соблюдение этого порядка выполнения.

Чаще всего это проявляется в так называемой "гонке данных" (data race), когда одна конкурентная операция пытается прочитать переменную, в то время как в какой-то неопределённый момент времени другая конкурентная операция пытается записать значение в эту же переменную.

Приведём простой пример:
```go
var data int
go func() {
    data++
}()
if data == 0 {
    fmt.Printf("the value is %v.\n", data)
}
```

В Go для параллельного выполнения функций используется ключевое слово go, которое создает так называемую горутину (подробнее в разделе "Горутины").

Рассмотрим пример, где строки 3 и 5 пытаются получить доступ к переменной data без гарантии порядка выполнения. Возможные сценарии выполнения:

- Ничего не выводится - строка 3 выполнилась до строки 5
- Выводится "the value is 0" - строки 5-6 выполнились до строки 3
- Выводится "the value is 1" - строка 5 выполнилась до 3, но 3 выполнилась до 6

## Почему возникают гонки данных? (race conditions)

Как вы можете видеть, всего несколько строк неправильного кода могут внести огромную нестабильность
в вашу программу.

В большинстве случаев гонки данных возникают, потому что разработчики думают о
коде последовательно. Они предполагают, что поскольку строка кода находится перед другой,
она будет запущена первой. Они предполагают, что вышеприведенная горутина будет запланирована и выполнена
до того, как переменная data будет прочитана в операторе if.

При написании параллельного кода вам нужно тщательно перебирать возможные
сценарии. Если вы не используете некоторые из методов, которые мы рассмотрим далее в книге,
у вас нет гарантий, что ваш код будет запущен в том порядке, в котором он указан в исходном
коде.

Иногда я нахожу полезным представить, что между вызываемыми операциями проходит большой период.
Представьте, что между вызовом горутины и ее выполнением пройдет час. Как тогда поведет себя оставшаяся часть кода?
А что, если бы между успешным выполнением горутины и достижением программой оператора if
прошел час?
Мне помогает такой подход, потому что для компьютера масштаб может быть
другим, но смысл от этого не теряется.
Но такая мысль приводит разработчика в ловушку разбрасывания sleep по всему коду. Как им кажется, это решает проблемы с параллелизмом. Давайте попробуем это в предыдущей программе:

```go
var data int
go func() { data++ }()
time.Sleep(1*time.Second) // This is bad!
if data == 0 {
    fmt.Printf("the value is %v.\n" data)
}
```

Решили ли мы нашу гонку данных? Нет. На самом деле, все три результата все еще могут возникнуть из этой программы, просто это становится все менее вероятным. Чем дольше мы спим между вызовом нашей горутины и проверкой значения данных, тем ближе наша программа становится к достижению корректности, но эта вероятность асимптотически приближается к логической корректности; она никогда не будет логически корректной.
В дополнение к этому, мы теперь внесли неэффективность в наш алгоритм. Теперь нам нужно спать одну секунду, чтобы повысить вероятность того, что мы не увидим нашу гонку данных. Если бы мы использовали правильные инструменты, нам, возможно, вообще не пришлось бы ждать, или ожидание могло бы составлять всего
микросекунду.
Вывод здесь в том, что вы всегда должны стремиться к логической корректности. 

Внедрение time.Sleep() в ваш код может быть удобным способом отладки параллельных программ, но это не решение.

Состояние гонки — один из самых коварных типов ошибок параллелизма, потому что они
могут не проявляться до тех пор, пока код не будет запущен в производство. Они
обычно вызваны изменением среды, в которой выполняется код, или
беспрецедентным событием. В этих случаях код, кажется, ведет себя правильно,
но на самом деле существует просто очень высокая вероятность того, что операции будут выполнены в
порядке. Рано или поздно программа будет иметь непредвиденные последствия.

## Атомарность

Когда что-то считается атомарным или имеет свойство атомарности, это
означает, что в контексте, в котором оно работает, оно неделимо или непрерываемо.

Так что же это на самом деле означает, и почему это важно знать при работе с
параллельным кодом?

Первое, что очень важно, — это слово «контекст». Что-то может быть атомарным
в одном контексте, но не в другом. Операции, которые являются атомарными в контексте вашего
процесса, могут не быть атомарными в контексте операционной системы; операции, которые являются
атомарными в контексте операционной системы, могут не быть атомарными в контексте вашей
машины; и операции, которые являются атомарными в контексте вашей
машины, могут не быть атомарными в контексте вашего приложения. Другими словами,
атомарность операции может меняться в зависимости от текущей определенной области действия.
Этот факт может работать как за, так и против вас!

Когда вы думаете об атомарности, очень часто первое, что вам нужно сделать, это определить
контекст или область действия, в которой операция будет считаться атомарной. Все
следует из этого.

---
### Интересный факт

В 2006 году игровая компания Blizzard успешно подала в суд на MDY Industries на
6 000 000 долларов США за создание программы под названием «Glider», которая автоматически
играла в их игру World of Warcraft без вмешательства пользователя. Такие типы программ обычно называют «ботами» (сокращение от robots).
В то время в World of Warcraft была античит-программа под названием «Warden», которая
запускалась в любое время, когда вы играли в игру. Помимо прочего, Warden сканировал
память хост-машины и запускал эвристику для поиска программ,
которые, по-видимому, использовались для мошенничества.
Glider успешно избежал этой проверки, воспользовавшись концепцией атомарного
контекста. Warden считал сканирование памяти на машине атомарной операцией, но Glider использовал аппаратные прерывания, чтобы скрыть себя до начала этого сканирования! Сканирование памяти Уорденом было атомарным в контексте процесса, но не в контексте операционной системы.

---

Теперь давайте рассмотрим термины «неделимый» и «непрерываемый». Эти термины означают, что
в контексте, который вы определили, что-то, что является атомарным, произойдет полностью,
без того, чтобы что-либо происходило в этом контексте одновременно. Это все еще труднопроизносимо, поэтому
давайте рассмотрим пример:
```go
i++
```

Это такой простой пример, какой только можно придумать, и тем не менее он легко демонстрирует концепцию атомарности. Он может выглядеть атомарным, но краткий анализ показывает несколько операций:
- Извлечь значение i.
- Увеличить значение i.
- Сохранение значения i.

Хотя каждая из этих операций по отдельности является атомарной, комбинация этих трех может
не быть таковой, в зависимости от вашего контекста. Это раскрывает интересное свойство атомарных операций: их объединение не обязательно приводит к более крупной атомарной операции. Сделать операцию атомарной зависит от того, в каком контексте вы хотите, чтобы она была атомарной. Если ваш контекст — это программа без параллельных процессов, то этот код является
атомарным в этом контексте. Если ваш контекст — это goroutine, которая не раскрывает i
другим goroutine, то этот код является атомарным.

Так почему же нас это волнует? Атомарность важна, потому что если что-то является атомарным, то неявно
оно безопасно в параллельных контекстах. Это позволяет нам составлять логически правильные программы и, как мы увидим позже, может даже служить способом оптимизации параллельных программ.

Большинство операторов не являются атомарными, не говоря уже о функциях, методах и программах.
Если атомарность является ключом к составлению логически правильных программ, а большинство операторов не являются
атомарными, как нам согласовать эти два оператора? Мы углубимся в это позже, но
говоря короче, мы можем форсировать атомарность, используя различные методы. 
Суть данного искусства - определить, какие области вашего кода должны быть атомарными и на каком уровне
детализации. Некоторые из этих проблем мы обсудим в следующем разделе.

## Синхронизация доступа к памяти.

Допустим, у нас есть гонка данных: два параллельных процесса пытаются получить доступ к
одной и той же области памяти, и способ, которым они получают доступ к памяти, не является атомарным. Наш
предыдущий пример простой гонки данных будет работать хорошо с несколькими модификациями:

```go
var data int
go func() { data++}()
if data == 0 {
fmt.Println("the value is 0.")
} else {
fmt.Printf("the value is %v.\n", data)
}
```

Мы добавили здесь предложение else, чтобы независимо от значения данных мы всегда
получали какой-то вывод. Помните, что, как написано, есть гонка данных, и вывод программы будет полностью недетерминированным.

На самом деле, есть название для раздела вашей программы, которому нужен исключительный доступ к
общему ресурсу. Это называется критической секцией(критическим разделом). В этом примере у нас есть три критических секции:

- Наша goroutine, которая увеличивает переменные data.
- Наш оператор if, который проверяет, равно ли значение data нулю.
- Наш оператор fmt.Printf, который извлекает значение data для вывода.

Существуют различные способы защиты критических секций вашей программы, и у Go есть несколько
лучших идей, как с этим справиться, но один из способов решения этой проблемы — синхронизировать доступ к памяти между вашими критическими разделами. Давайте посмотрим, как это
выглядит. 

Следующий код не является идиоматическим Go (и я не предлагаю вам пытаться решать ваши
проблемы гонки данных таким образом), но он очень просто демонстрирует синхронизацию доступа к памяти. Если какие-либо типы, функции или методы в этом примере вам незнакомы, это нормально. Сосредоточьтесь на концепции синхронизации доступа к памяти, следуя выноскам.

```go
var memoryAccess sync.Mutex // 1
var value int
go func() {
    memoryAccess.Lock() // 2
    value++
    memoryAccess.Unlock() // 3
}()
memoryAccess.Lock() // 4
if value == 0 {
    fmt.Printf("the value is %v.\n", value)
} else {
    fmt.Printf("the value is %v.\n", value)
}
memoryAccess.Unlock() // 5
```
1) Здесь мы добавляем переменную, которая позволит нашему коду синхронизировать доступ к памяти переменной data. Мы подробно рассмотрим тип sync.Mutex в разделе «Пакет sync».
2) Здесь мы объявляем, что пока мы не объявим иное, наша goroutine должна иметь
исключительный доступ к этой памяти.
3) Здесь мы объявляем, что goroutine закончила работу с этой памятью.
4) Здесь мы снова объявляем, что следующие условные операторы должны иметь
исключительный доступ к памяти переменной data.
5) Здесь мы объявляем, что мы снова закончили работу с этой памятью.

В этом примере мы создали соглашение, которому должны следовать разработчики. В любое время, когда разработчики хотят получить доступ к памяти переменной данных, они должны сначала вызвать Lock, а когда закончат, они должны вызвать Unlock. Код между этими двумя операторами может
предположить, что у него есть исключительный доступ к данным; мы успешно синхронизировали доступ к
памяти. Также обратите внимание, что если разработчики не следуют этому соглашению, у нас нет гарантии исключительного доступа! Мы вернемся к этой идее в разделе «Ограничение».

Вы могли заметить, что хотя мы решили нашу гонку данных, мы на самом деле не решили наше состояние гонки! Порядок операций в этой программе по-прежнему недетерминирован; мы просто немного сузили область недетерминизма. В этом примере либо горутина выполнится первой, либо оба наших блока if и else. Мы по-прежнему
не знаем, что произойдет первым при любом заданном выполнении этой программы. Позже мы рассмотрим инструменты для правильного решения подобных проблем.

На первый взгляд это кажется довольно простым: если вы обнаружили, что у вас есть критические разделы, добавьте точки
для синхронизации доступа к памяти! Легко, не так ли? Ну... в некотором роде.

Это правда, что вы можете решить некоторые проблемы, синхронизировав доступ к памяти,
но, как мы только что увидели, это не решает гонки данных или логическую корректность. Кроме того, это также может создавать проблемы с обслуживанием и производительностью.

Обратите внимание, что ранее мы упоминали, что создали соглашение для объявления нам
необходимо исключительное право доступа к некоторой памяти. Соглашения хороши, но их также легко
игнорировать, особенно в разработке программного обеспечения, где требования бизнеса иногда перевешивают благоразумие. Синхронизируя доступ к памяти таким образом,
вы рассчитываете, что все другие разработчики будут следовать этому соглашению сейчас и в будущем. Это довольно сложная задача. К счастью, далее в этой книге мы также рассмотрим
некоторые способы, которыми мы можем помочь нашим коллегам добиться большего успеха.

Таким образом синхронизация доступа к памяти также имеет последствия для производительности. Мы сохраним ньюансы для дальнейшего изучения пакета синхронизации в разделе «Пакет синхронизации», но вызовы Lock, которые вы видите, могут замедлить нашу программу. Каждый раз, когда мы выполняем одну из этих операций, наша программа останавливается на некоторое время. Это поднимает два вопроса:
- Мои критические разделы входят и выходят из них повторно?
- Какого размера должны быть мои критические разделы?

Ответить на эти два вопроса в контексте вашей программы — это искусство, и это добавляет сложности в синхронизацию доступа к памяти.
Синхронизация доступа к памяти также имеет некоторые общие проблемы с другими методами моделирования параллельных задач, и мы обсудим их в следующем разделе.

## Deadlocks, Livelocks, and Starvation. Взаимоблокировки, блокировки в режиме реального времени и голодание

В предыдущих разделах обсуждалось корректное выполнение программы, поскольку, если
возникающие проблемы решаются правильно, ваша программа никогда не даст неверного ответа.

К сожалению, даже если вы успешно справитесь с этими классами проблем, есть еще один
класс проблем, с которыми нужно бороться: взаимоблокировки, блокировки в режиме реального времени и голодание. 
Все эти проблемы влияют на гарантию того, что ваша программа всегда выполняет что-то полезное. Если с ними не справиться должным образом, ваша программа может войти в состояние, в котором она вообще перестанет функционировать.

### Deadlock(Взаимоблокировка)

Взаимоблокированная программа — это программа, в которой все параллельные процессы ждут друг друга. В этом состоянии программа никогда не восстановится без внешнего вмешательства.

Если это звучит страшно, то так оно и есть! Go runtime пытается выполнить свою часть работы и
обнаружит некоторые взаимоблокировки (все горутины должны быть заблокированы или «спящими»), но это не
сильно поможет вам предотвратить взаимоблокировки.

Чтобы помочь закрепить, что такое взаимоблокировка, давайте сначала рассмотрим пример. Опять же, пока игнорируйте
любые типы, функции, методы или пакеты, которые вы не знаете, и просто следуйте
выноскам кода

```go
type value struct {
    mu sync.Mutex
    value int
}

var wg sync.WaitGroup
printSum := func(v1, v2 *value) {
    defer wg.Done()
    v1.mu.Lock() // 1
    defer v1.mu.Unlock() // 2
	
    time.Sleep(2*time.Second) //3
    v2.mu.Lock()
    defer v2.mu.Unlock()
	
    fmt.Printf("sum=%v\n", v1.value + v2.value)
}

var a, b value
wg.Add(2)
go printSum(&a, &b)
go printSum(&b, &a)
wg.Wait()
```

1) Здесь мы пытаемся войти в критическую секцию для входящего значения.
2) Здесь мы используем оператор defer для выхода из критической секции до возврата printSum.
3) Здесь мы спим в течение определенного периода времени, чтобы имитировать работу (и вызвать взаимоблокировку).

4) Если бы вы попытались запустить этот код, вы, вероятно, увидели бы:
фатальная ошибка: все горутины спят — взаимоблокировка!
Почему? Если вы посмотрите внимательно, вы увидите проблему синхронизации в этом коде. Ниже приведено графическое представление того, что происходит. Прямоугольники представляют функции, горизонтальные
линии — вызовы этих функций, а вертикальные
полосы — время жизни функции в начале
графика (рисунок 1-1).

![img.png](img/1-1.png)

По сути, мы создали две шестеренки, которые не могут вращаться вместе: наш первый вызов print
Sum блокирует a, а затем пытается заблокировать b, но в то же время наш второй вызов print
Sum заблокировал b и попытался заблокировать a. Обе горутины бесконечно ждут друг
друга.

---
### Irony

Чтобы упростить этот пример, я использую time.Sleep для запуска взаимоблокировки. Однако, это вводит состояние гонки! Можете ли вы его найти?
Логически «идеальная» взаимоблокировка потребует правильной синхронизации.(На самом деле у нас нет гарантии, в каком порядке будут запущены горутины или сколько времени им потребуется для запуска.
Возможно, хотя и маловероятно, что одна горутина может получить и снять обе блокировки до начала работы другой,
тем самым избежав deadlock-а!)

---

Кажется довольно очевидным, почему возникает эта взаимоблокировка, когда мы представляем ее графически,
но мы бы выиграли от более строгого определения. 

Оказывается, есть
несколько условий, которые должны присутствовать для возникновения взаимоблокировок, и в 1971 году Эдгар Коффман перечислил эти условия в своей статье. Эти условия теперь известны как
Условия Коффмана и являются основой для методов, которые помогают обнаруживать, предотвращать и
исправлять взаимоблокировки.

Условия Коффмана следующие:
- Взаимное исключение. Параллельный процесс имеет исключительные права на ресурс в любой момент времени.
- Условие ожидания. Параллельный процесс должен одновременно удерживать ресурс и ожидать
дополнительный ресурс.
- Нет вытеснения. Ресурс, удерживаемый параллельным процессом, может быть освобожден только этим процессом,
поэтому он удовлетворяет этому условию.
- Круговое ожидание. Конкурентный процесс (P1) должен ожидать цепочку других конкурентных процессов (P2), которые в свою очередь ждут его (P1), поэтому он удовлетворяет этому последнему условию

Давайте рассмотрим нашу придуманную программу и определим, соответствует ли она всем четырем условиям:
1. Функция printSum требует исключительных прав как на a, так и на b, поэтому она
   выполняет это условие.
2. Поскольку printSum удерживает либо a, либо b и ожидает второго, она
   выполняет это условие.
3. Мы не дали возможности нашим горутинам быть вытесненными.
4. Наш первый вызов printSum ожидает нашего второго вызова, и наоборот.

Да, у нас определенно есть взаимоблокировка.

Эти законы также позволяют нам предотвращать взаимоблокировки. Если мы гарантируем, что хотя бы одно из этих
условий не выполняется, мы можем предотвратить возникновение взаимоблокировок. К сожалению, на практике эти условия может быть трудно рассуждать, и, следовательно, их трудно предотвратить. Интернет усеян вопросами от разработчиков, таких как вы и я, которые задаются вопросом,
почему фрагмент кода взаимоблокируется. Обычно это довольно очевидно, когда кто-то указывает на это, но часто это требует еще одной пары глаз. Мы поговорим о том, почему это так, в разделе «Определение безопасности параллелизма».

## Livelock
Livelock — это программы, которые активно выполняют параллельные операции, но эти
операции ничего не делают для продвижения состояния программы вперед.

Вы когда-нибудь были в коридоре, идя к другому человеку? Она отходит в одну
сторону, чтобы пропустить вас, но вы только что сделали то же самое. Поэтому вы отходите в другую сторону, но
она тоже сделала то же самое. Представьте, что это продолжается вечно, и вы поймете livelock.

Давайте напишем код, который поможет продемонстрировать этот сценарий. Сначала мы настроим
несколько вспомогательных функций, которые упростят пример. Чтобы получить работающий
пример, в коде здесь используется несколько тем, которые мы еще не рассмотрели. Я не советую
пытаться понять его подробно, пока вы не освоите пакет синхронизации. Вместо этого я рекомендую следовать выноскам кода, чтобы понять основные моменты, а затем обратить внимание на второй блок кода, который содержит
суть примера.

```go
cadence := sync.NewCond(&sync.Mutex{})
go func() {
   for range time.Tick(1*time.Millisecond) {
    cadence.Broadcast()
   }
}()

takeStep := func() {
   cadence.L.Lock()
   cadence.Wait()
   cadence.L.Unlock()
}

tryDir := func(dirName string, dir *int32, out *bytes.Buffer) bool { // 1
   fmt.Fprintf(out, " %v", dirName)
   atomic.AddInt32(dir, 1) // 2
   takeStep() // 3
   if atomic.LoadInt32(dir) == 1 {
      fmt.Fprint(out, ". Success!")
      return true
   }
   takeStep()
   atomic.AddInt32(dir, -1) // 4
   return false
}

var left, right int32
tryLeft := func(out *bytes.Buffer) bool { return tryDir("left", &left, out) }
tryRight := func(out *bytes.Buffer) bool { return tryDir("right", &right, out) }
```

1) tryDir позволяет человеку попытаться двигаться в направлении и возвращает, были ли они успешными. Каждое направление представлено как количество людей, пытающихся двигаться в этом направлении, dir.
2) Сначала мы объявляем о своем намерении двигаться в направлении, увеличивая это направление на единицу. Мы подробно обсудим атомарный пакет в Главе 3. На данный момент все, что вам нужно знать, это то, что операции этого пакета являются атомарными.
3) Чтобы пример продемонстрировал оперативную блокировку, каждый человек должен двигаться с одинаковой скоростью, или каденсом. takeStep имитирует постоянный каденс между всеми участниками.
4) Здесь человек понимает, что он не может двигаться в этом направлении, и сдается. Мы указываем на это, уменьшая это направление на единицу.

```go
walk := func(walking *sync.WaitGroup, name string) {
   var out bytes.Buffer
   defer func() { fmt.Println(out.String()) }()
   defer walking.Done()
   
   fmt.Fprintf(&out, "%v is trying to scoot:", name)
   
   for i := 0; i < 5; i++ { // 1
      if tryLeft(&out) || tryRight(&out) { // 2
       return
      }
   }
   
   fmt.Fprintf(&out, "\n%v tosses her hands up in exasperation!", name)
}

var peopleInHallway sync.WaitGroup //3
peopleInHallway.Add(2)

go walk(&peopleInHallway, "Alice")
go walk(&peopleInHallway, "Barbara")

peopleInHallway.Wait()
```

1) Я установил искусственный предел на количество попыток, чтобы эта программа
завершилась. В программе, которая имеет оперативную блокировку, такого предела может не быть, поэтому
это проблема!
2) Сначала человек попытается сделать шаг влево, а если это не удается, он попытается сделать шаг
вправо.
3) Эта переменная предоставляет программе возможность ждать, пока оба человека
либо не смогут обойти друг друга, либо сдадутся.

Программа выведет:  
Alice is trying to scoot: left right left right left right left right left right   
Alice tosses her hands up in exasperation!  
Barbara is trying to scoot: left right left right left right left right
left right  
Barbara tosses her hands up in exasperation!

Вы можете видеть, что Алиса и Барбара продолжают мешать друг другу, прежде чем окончательно
сдаться.
Этот пример демонстрирует очень распространенную причину написания лайвлоков: два или более
одновременных процесса пытаются предотвратить тупик без координации. Если
люди в коридоре договорились друг с другом, что только один человек будет двигаться,
не было бы лайвлока: один человек стоял бы на месте, другой
двигался бы в другую сторону, и они продолжали бы идти.

По моему мнению, livelock сложнее обнаружить, чем deadlock, просто потому,
что может показаться, что программа выполняет работу. 

Если бы лайвлокированная программа работала на
вашей машине, и вы посмотрели на загрузку ЦП, чтобы определить, делает ли она что-нибудь, вы могли бы подумать, что это так. В зависимости от лайвлока она могла бы даже испускать другие сигналы, которые заставили бы вас думать, что она выполняет работу. И все же все это время ваша программа играла бы в вечную игру в коридорную перетасовку.
Livelocks — это подмножество более обширного набора проблем, называемых голоданием. Мы рассмотрим это далее.

## Starvation (Голодание)

Голодание — это любая ситуация, когда параллельный процесс не может получить все ресурсы, необходимые для выполнения работы.
Когда мы обсуждали блокировки, ресурс, которого не хватало каждой горутине, был
совместной блокировкой. Блокировки требуют отдельного обсуждения от голодания, потому что при блокировке все параллельные процессы одинаково голодают, и никакая работа не выполняется.
В более широком смысле, голодание обычно подразумевает, что есть один или несколько жадных параллельных процессов, которые несправедливо мешают одному или нескольким параллельным процессам
выполнять работу максимально эффективно или, может быть, вообще.
Вот пример программы с жадной горутиной и вежливой горутиной:

```go
var wg sync.WaitGroup
var sharedLock sync.Mutex
const runtime = 1*time.Second

greedyWorker := func() {
   defer wg.Done()
   var count int
   for begin := time.Now(); time.Since(begin) <= runtime; {
      sharedLock.Lock()
      time.Sleep(3*time.Nanosecond)
      sharedLock.Unlock()
      count++
   }
   fmt.Printf("Greedy worker was able to execute %v work loops\n", count)
}

politeWorker := func() {
   defer wg.Done()
   var count int
   for begin := time.Now(); time.Since(begin) <= runtime; {
      sharedLock.Lock()
      time.Sleep(1*time.Nanosecond)
      sharedLock.Unlock()
	  
      sharedLock.Lock()
      time.Sleep(1*time.Nanosecond)
      sharedLock.Unlock()
	  
      sharedLock.Lock()
      time.Sleep(1*time.Nanosecond)
      sharedLock.Unlock()
	  
      count++
   }
   fmt.Printf("Polite worker was able to execute %v work loops.\n", count)
}

wg.Add(2)
go greedyWorker()
go politeWorker()
wg.Wait()
```

Результат выполнения данной программы:  
Polite worker was able to execute 289777 work loops.  
Greedy worker was able to execute 471287 work loops

Жадный работник жадно удерживает общую блокировку на протяжении всего своего рабочего цикла, тогда как вежливый работник пытается заблокировать только тогда, когда это необходимо. Оба работника
выполняют одинаковый объем имитируемой работы (спя в течение трех наносекунд), но, как вы
можете видеть, за одинаковое количество времени жадный работник выполнил почти вдвое больше работы!

Если мы предположим, что у обоих работников критический раздел одинакового размера, вместо того, чтобы сделать вывод, что алгоритм жадного работника более эффективен (или что вызовы Lock и Unlock медленные — это не так), мы вместо этого придем к выводу, что жадный работник без необходимости расширил свое удержание общей блокировки за пределы своего критического раздела и мешает (через голодание) goroutine вежливого работника выполнять работу
эффективно.

Обратите внимание на нашу технику здесь для определения голодания: метрику. Голод является
хорошим аргументом для записи и выборки метрик. Один из способов обнаружить и решить проблему голодания — это записывать время выполнения работы, а затем определять,
настолько ли высока ваша скорость работы, как вы ожидаете.

---
### Поиск баланса

Стоит отметить, что предыдущий пример кода также может служить примером
производительности последствий синхронизации доступа к памяти. Поскольку синхронизация доступа к памяти обходится дорого, может быть выгодно расширить нашу
блокировку за пределы наших критических разделов. С другой стороны, делая это — как мы видели — мы
рискуем лишить другие параллельные процессы возможности.
Если вы используете синхронизацию доступа к памяти, вам придется найти баланс между
предпочтением грубой синхронизации для производительности и мелкой синхронизации для справедливости. Когда придет время настраивать производительность вашего приложения,
для начала я настоятельно рекомендую вам ограничить синхронизацию доступа к памяти только
критическими разделами; если синхронизация станет проблемой производительности, вы всегда можете расширить область действия. Гораздо сложнее пойти другим путем.
---

Итак, голодание может привести к тому, что ваша программа будет вести себя неэффективно или неправильно. Предыдущий
пример демонстрирует неэффективность, но если у вас есть параллельный процесс, который настолько
жаден, что полностью мешает другому параллельному процессу выполнять
работу, у вас на руках более серьезная проблема.
Мы также должны рассмотреть случай, когда голодание происходит извне процесса Go. Имейте в виду, что голодание может также применяться к ЦП, памяти, дескрипторам файлов,
подключениям к базе данных: любой общий ресурс, является кандидатом на голодание.

## Определение безопасности параллелизма

Определение безопасности параллелизма
Наконец, мы подошли к самому сложному аспекту разработки параллельного кода, к тому,
что лежит в основе всех остальных проблем: люди.    За каждой строкой кода стоит как минимум один
человек.

Как мы обнаружили, параллельный код сложен по множеству причин. Если вы разработчик и пытаетесь решить все эти проблемы, внедряя новую функциональность или исправляя ошибки в своей программе, может быть действительно сложно определить,
что делать правильно.
Если вы начинаете с чистого листа и вам нужно создать разумный способ моделирования
проблемного пространства, и задействован параллелизм, может быть сложно найти правильный уровень
абстракции. Как вы раскрываете параллелизм вызывающим? Какие методы вы
используете для создания решения, которое легко использовать и изменять? Каков правильный уровень
параллелизма для этой проблемы? Хотя есть способы структурированного мышления об этих проблемах, это остается искусством.

Как разработчик, взаимодействующий с существующим кодом, не всегда очевидно, какой код использует параллелизм, и как безопасно использовать код. Возьмем эту сигнатуру функции:
```go
// CalculatePi вычисляет цифры числа Pi между начальной и конечной
// позицией.
func CalculatePi(begin, end int64, pi *Pi)
```
Вычисление числа Pi с большой точностью лучше всего выполнять параллельно, но
этот пример вызывает много вопросов:
- Как мне это сделать с помощью этой функции?
- Я отвечаю за создание нескольких одновременных вызовов этой функции?
- Похоже, что все экземпляры функции будут работать непосредственно с экземпляром Pi, адрес которого я передаю; отвечаю ли я за синхронизацию доступа
к этой памяти, или тип Pi справляется с этим за меня?

Одна функция поднимает все эти вопросы. Представьте себе программу любого среднего размера, и
вы можете начать понимать сложности, которые может создавать параллелизм.

Комментарии могут творить чудеса здесь. Что, если бы функция CalculatePi была бы написана так:

```go
// CalculatePi calculates digits of Pi between the begin and end
// place.
//
// Internally, CalculatePi will create FLOOR((end-begin)/2) concurrent
// processes which recursively call CalculatePi. Synchronization of
// writes to pi are handled internally by the Pi struct.
func CalculatePi(begin, end int64, pi *Pi)
```

Теперь мы понимаем, что можем вызывать функцию просто и не беспокоиться о параллелизме или синхронизации. Важно, что комментарий охватывает следующие аспекты:
- Кто отвечает за параллелизм?
- Как проблемное пространство отображается на примитивы параллелизма?
- Кто отвечает за синхронизацию?

При раскрытии функций, методов и переменных в проблемных пространствах, которые включают параллелизм, сделайте своим коллегам и себе в будущем одолжение: отвлекитесь в сторону многословных комментариев и постарайтесь охватить эти три аспекта.

Также учтите, что, возможно, неоднозначность в этой функции предполагает, что мы неправильно ее смоделировали. Может быть, вместо этого нам следует использовать функциональный подход и убедиться, что наша функция не имеет побочных эффектов:
```go
func CalculatePi(begin, end int64) []uint
```
Одна только сигнатура этой функции снимает любые вопросы синхронизации, но все еще оставляет вопрос о том, используется ли параллелизм. Мы можем изменить сигнатуру
снова, чтобы выдать еще один сигнал о том, что происходит:
```go
func CalculatePi(begin, end int64) <-chan uint
```

Здесь мы видим первое использование того, что называется каналом. По причинам, которые мы рассмотрим позже в разделе «Каналы» на странице 64, это предполагает, что CalculatePi будет иметь по крайней мере
одну горутину и что нам не следует беспокоиться о создании своей собственной.
Эти изменения затем имеют последствия для производительности, которые необходимо
учесть, и мы возвращаемся к проблеме баланса ясности и производительности.

Ясность важна, потому что мы хотим сделать так, чтобы люди, работающие с этим кодом в будущем, поступали правильно,
а производительность важна по очевидным причинам. Эти два понятия не являются взаимоисключающими, но их трудно смешивать.
Теперь рассмотрим эти трудности в общении и попытаемся масштабировать их до проектов размером с команду.

Ого, это проблема...

Хорошей новостью является то, что Go добился прогресса в упрощении решения подобных проблем. Сам язык способствует читаемости и простоте. То, как он поощряет написание вашего параллельного кода, поощряет корректность, компонуемость и масштабируемость. Фактически, то, как Go обрабатывает параллелизм, может помочь более четко выразить проблемные области! Давайте рассмотрим, почему это так.

### Простое под видом сложного

До сих пор я нарисовал довольно мрачную картину. Параллелизм, безусловно, является сложной областью в компьютерной науке, но я хочу оставить вас с надеждой: эти проблемы не являются неразрешимыми, и с примитивами параллелизма Go вы можете более безопасно и ясно выразить
ваши параллельные алгоритмы. Трудности времени выполнения и коммуникации, которые мы обсудили, никоим образом не решены Go, но они были значительно упрощены. В следующей главе мы узнаем, как был достигнут этот прогресс.

Здесь давайте потратим немного времени на изучение идеи о том, что примитивы параллелизма Go могут
фактически упростить моделирование проблемных областей и более
ясно выразить алгоритмы.

Среда выполнения Go выполняет большую часть тяжелой работы и обеспечивает основу для большинства
прелестей параллелизма Go. Мы отложим обсуждение того, как все это работает, до главы 6, а здесь обсудим, как все это облегчает вам жизнь.

Сначала обсудим параллельный сборщик мусора Go с низкой задержкой. Среди разработчиков часто возникают споры о том,
хорошо ли иметь сборщики мусора в языке. Критики предполагают, что сборщики мусора мешают работе в любой проблемной области,
требующей производительности в реальном времени или детерминированного профиля производительности, —
что приостановка всех действий в программе для очистки мусора просто неприемлема.

Хотя в этом есть некоторая заслуга, отличная работа, проделанная над сборщиком мусора Go,
резко сократила аудиторию, которой нужно беспокоиться о мелочах работы сборщика мусора Go. Начиная с версии Go 1.8, паузы при сборке мусора обычно составляют от 10 до 100 микросекунд!

Как это вам помогает? Управление памятью может быть еще одной сложной проблемой
в области компьютерных наук, и в сочетании с параллелизмом может стать
чрезвычайно сложно писать правильный код. Если вы относитесь к большинству разработчиков,
которым не нужно беспокоиться о паузах длительностью всего 10 микросекунд, Go значительно облегчил использование параллелизма в вашей программе, не заставляя вас управлять памятью, не говоря уже о параллельных процессах.

Среда выполнения Go также автоматически обрабатывает мультиплексирование параллельных операций в
потоки операционной системы. Это сложно, и мы увидим, что именно это означает, в
разделе «Горутины» на странице 37. Чтобы понять, как это
вам помогает, все, что вам нужно знать, это то, что он позволяет вам напрямую отображать параллельные проблемы в параллельные конструкции вместо того, чтобы разбираться с мелочами запуска и управления потоками, а также равномерного отображения логики по доступным потокам.

Например, вы пишете веб-сервер и хотите, чтобы каждое принятое соединение
обрабатывалось одновременно с каждым другим соединением. В некоторых языках, прежде чем ваш
веб-сервер начнет принимать соединения, вам, скорее всего, придется создать коллекцию
потоков, обычно называемую пулом потоков, а затем сопоставить входящие соединения с
потоками. Затем, в каждом созданном вами потоке, вам нужно будет перебрать все соединения в этом потоке, чтобы убедиться, что все они получают некоторое время ЦП. Кроме того, вам придется написать логику обработки соединений так, чтобы ее можно было приостановить, чтобы она
справедливо делилась с другими соединениями.

Ух ты! Напротив, в Go вы бы написали функцию, а затем добавили к ее вызову ключевое слово go. Среда выполнения автоматически обрабатывает все остальное, что мы обсуждали! Когда вы проходите процесс проектирования своей программы, в рамках какой модели, по вашему мнению, вы, скорее всего, достигнете параллелизма? Какая, по вашему мнению, скорее всего, окажется правильной?
Примитивы параллелизма Go также упрощают составление более крупных задач. Как мы увидим
в разделе «Каналы», примитив канала Go обеспечивает компонуемый,
безопасный для параллелизма способ взаимодействия между параллельными процессами.

Я умолчал о большинстве деталей того, как все это работает, но я хотел дать
вам некоторое представление о том, как Go предлагает вам использовать параллелизм в вашей программе, чтобы помочь
вам решать ваши проблемы понятным и производительным способом. В следующей главе мы обсудим философию параллелизма и то, почему Go так много правильного. Если вы хотите
перейти к коду, вы можете перейти к Главе 3.

---

# Глава 2
# Моделирование вашего кода: коммуникация. Последовательные процессы

## Разница между конкурентностью и параллелизмом

Тот факт, что конкурентность отличается от параллелизма, часто упускается из виду или неправильно понимается. В разговорах между многими разработчиками эти два термина часто используются взаимозаменяемо, чтобы обозначить «что-то, что выполняется одновременно с чем-то другим».
Иногда использование слова «параллельный» в этом контексте является правильным, но обычно, если разработчики обсуждают код, им действительно следует использовать слово «конкурентный».

Причина для различения выходит далеко за рамки педантизма. Разница между конкурентностью и параллелизмом оказывается очень мощной абстракцией при моделировании
вашего кода, и Go в полной мере использует это преимущество. Давайте рассмотрим, чем отличаются эти две концепции, чтобы мы могли понять силу этой абстракции. Начнем с очень простого утверждения:

Конкурентность — это свойство кода; параллелизм — это свойство работающей программы.

Это своего рода интересное различие. Разве мы обычно не думаем об этих двух
вещах одинаково? Мы пишем наш код так, чтобы он выполнялся параллельно. Верно?

Что ж, давайте подумаем об этом секунду. Если я пишу свой код с намерением, чтобы два
куска программы выполнялись параллельно, есть ли у меня гарантия, что это действительно
произойдет параллельно, когда программа будет запущена? Что произойдет, если я запущу код на машине с
только одним ядром? Некоторые из вас могут подумать: он будет выполняться параллельно, но это не так!
Кажется, что части нашей программы работают параллельно, но на самом деле они
выполняются последовательно быстрее, чем можно различить. Контекст ЦП
переключается, чтобы разделить время между различными программами, и на достаточно грубой гранулярности времени, задачи, по-видимому, выполняются параллельно. Если бы мы запустили тот же
двоичный файл на машине с двумя ядрами, фрагменты программы могли бы фактически выполняться
параллельно.

Это раскрывает несколько интересных и важных вещей. Во-первых, мы не пишем
параллельный код, только конкурентный код, который, как мы надеемся, будет выполняться параллельно. Еще раз,
параллелизм — это свойство среды выполнения нашей программы, а не кода.

Вторая интересная вещь заключается в том, что мы видим, что может быть, даже не желательно знать, выполняется ли наш конкурентный код на самом деле параллельно. 
Это становится возможным только благодаря слоям абстракции, которые лежат под моделью нашей программы:
примитивам конкурентности, среде выполнения программы, операционной системе, платформе, на которой работает операционная система (в случае гипервизоров, контейнеров и виртуальных
машин) и, в конечном счете, ЦП. Эти абстракции позволяют нам различать параллелизм и конкурентность, и в конечном итоге дают нам силу и гибкость для самовыражения.
Мы вернемся к этому.

Третья и последняя интересная вещь заключается в том, что параллелизм является функцией времени или контекста. Помните, в разделе «Атомарность» мы обсуждали концепцию контекста?
Там контекст определялся как границы, по которым операция считалась
атомарной. Здесь он определяется как границы, по которым две или более операций можно было
считать параллельными.

Например, если бы наш контекст был промежутком в пять секунд, и мы запустили две операции,
каждая из которых выполнялась по секунде, мы бы считали, что операции выполнялись параллельно. Если бы наш контекст длился одну секунду, мы бы считали, что операции выполнялись
последовательно.

Возможно, нам не очень поможет переопределение нашего контекста в терминах временных срезов, но помните, что контекст не ограничен временем. Мы можем определить контекст как
процесс, в котором работает наша программа, поток ее операционной системы или ее машина. Это
важно, потому что определяемый вами контекст тесно связан с концепцией конкурентности и корректности. Так же, как атомарные операции можно считать атомарными в зависимости от определяемого вами контекста, параллельные операции являются корректными в зависимости от определяемого вами контекста. Все это относительно.


Это немного абстрактно, поэтому давайте рассмотрим пример. Допустим, что контекст, который мы обсуждаем, — это
ваш компьютер. Оставив в стороне теоретическую физику, мы можем обоснованно ожидать, что процесс,
выполняющийся на моей машине, не повлияет на логику процесса на вашей машине.
Если мы оба запустим процесс калькулятора и начнем выполнять простую арифметику,
выполняемые мной вычисления не должны влиять на вычисления, выполняемые вами.
Это глупый пример, но если мы разберем его, то увидим все детали в игре: наши машины
являются контекстом, а процессы — параллельными операциями. В этом случае мы решили моделировать наши параллельные операции, думая о мире в терминах отдельных компьютеров, операционных систем и процессов. Эти абстракции позволяют нам уверенно утверждать правильность.

---

### Неужели это действительно глупый пример?

Использование отдельных компьютеров кажется надуманным примером для доказательства, но персональные компьютеры не всегда были столь распространены! До конца 1970-х годов мэйнфреймы
были нормой, и общим контекстом, который разработчики использовали при одновременном обдумывании проблем, был процесс программы.
Теперь, когда многие разработчики работают с распределенными системами, все смещается в другую сторону! Теперь мы начинаем мыслить в терминах гипервизоров, контейнеров и виртуальных машин как наших параллельных контекстов.

---

Мы можем обоснованно ожидать, что один процесс на машине останется незатронутым процессом на другой машине (предполагая, что они не являются частью одной и той же распределенной системы),
но можем ли мы ожидать, что два процесса на одной машине не повлияют на логику друг
друга? Процесс A может перезаписать некоторые файлы, которые читает процесс B, или в незащищенной
ОС процесс A может даже повредить память, которую читает процесс B. Делать это намеренно
— вот как работают многие эксплойты.

Тем не менее, на уровне процесса все остается относительно легко для размышлений. Если мы вернемся к
нашему примеру с калькулятором, все еще разумно ожидать, что два пользователя, запускающие два процесса калькулятора на одной машине, должны обоснованно ожидать, что их операции
будут логически изолированы друг от друга. К счастью, граница процесса и ОС
помогают нам думать об этих проблемах логически. Но мы можем видеть, что разработчик начинает обременяться некоторыми проблемами параллелизма, и эта проблема
только усугубляется. Что, если мы спустимся еще на один уровень ниже, к границе потока ОС? Именно здесь все
проблемы, перечисленные в разделе «Почему сложно параллелизм?» на странице 4,
действительно проявляются: состояния гонки, взаимоблокировки, блокировки в реальном времени и голодание. Если бы у нас был
один процесс калькулятора, в который все пользователи на машине имели представления, было бы
труднее правильно реализовать параллельную логику. Нам пришлось бы начать беспокоиться о
синхронизации доступа к памяти и извлечении правильных результатов для правильного
пользователя.

Происходит то, что по мере того, как мы начинаем спускаться по стеку абстракций, проблема моделирования вещей одновременно становится и более сложной для рассуждений, и более важной. И наоборот, наши абстракции становятся для нас все более и более
важными. Другими словами, чем сложнее правильно реализовать параллелизм, тем
важнее иметь доступ к примитивам параллелизма, которые легко составить. К сожалению, большая часть параллельной логики в нашей отрасли написана на одном из самых высоких уровней абстракции: потоках ОС.

До того, как Go был впервые представлен публике, на этом заканчивалась цепочка абстракций для большинства популярных языков программирования. Если вы хотели написать параллельный код, вы моделировали свою программу в терминах потоков и синхронизировали
доступ к памяти между ними. Если у вас было много вещей, которые вам нужно было моделировать
одновременно, и ваша машина не могла обработать столько потоков, вы создавали
пул потоков и мультиплексировали свои операции в пул потоков.

Go добавил еще одно звено в эту цепочку: goroutine. Кроме того, Go позаимствовал
несколько концепций из работы знаменитого ученого-компьютерщика Тони Хоара и ввел новые примитивы для использования, а именно каналы.
Если продолжить ход рассуждений, которому мы следовали, мы бы предположили, что введение еще одного уровня абстракции ниже потоков ОС принесет с собой больше трудностей, но интересно то, что это не так. На самом деле это упрощает задачу. Это
потому что мы на самом деле не добавили еще один уровень абстракции поверх потоков ОС,
мы вытеснили их.

Потоки, конечно, все еще есть, но мы обнаруживаем, что нам редко приходится думать о нашем
проблемном пространстве с точки зрения потоков ОС. Вместо этого мы моделируем вещи в горутинах и
каналах, а иногда и в общей памяти. Это приводит к некоторым интересным свойствам,
которые мы исследуем в разделе «Как это вам поможет» на странице 29. Но сначала давайте
подробнее рассмотрим, откуда Go взял многие свои идеи — статью, лежащую в основе примитивов параллелизма Go: основополагающую статью Тони Хоара «Общение последовательных процессов».

## Что такое CSP?
Когда обсуждают Go, вы часто слышите, как люди бросаются аббревиатурой CSP.
Часто на одном дыхании ее превозносят как причину успеха Go или панацею для параллельного программирования. Этого достаточно, чтобы люди, которые не знают, что такое CSP,
начали думать, что компьютерная наука открыла какую-то новую технику, которая волшебным образом делает программирование параллельных программ таким же простым, как написание процедурных.

Хотя CSP действительно упрощает вещи и делает программы более надежными, к сожалению, это
не чудо. Так что же это? Что всех так взволновало?

CSP означает «Communicating Sequential Processes» («Взаимодействующие последовательные процессы»), что является одновременно техникой и
названием статьи, в которой она была представлена. В 1978 году Чарльз Энтони Ричард Хоар
опубликовал статью в Association for Computing Machinery (более
популярно называемой ACM). В этой статье Хоар предполагает, что ввод и вывод — это два упускаемых из виду примитива программирования, особенно в параллельном коде. В то время, когда Хоар написал эту статью, исследования по структурированию программ все еще велись, но большая часть этих усилий была направлена ​​на методы последовательного кода: обсуждалось использование оператора goto, и объектно-ориентированная парадигма начала принимать главенствующее место. Параллельные операции не были предметом особого внимания. Хоар решил исправить это, и так родилась его статья и CSP.

В статье 1978 года CSP был всего лишь простым языком программирования, созданным исключительно
для демонстрации мощи передачи последовательных процессов; на самом деле, он даже
говорит в статье:

Таким образом, концепции и обозначения, введенные в этой статье, не
должны рассматриваться как
подходящие для использования в качестве языка программирования, как для абстрактного, так и для конкретного программирования.

Хоар был глубоко обеспокоен тем, что методы, которые он представлял,
ничего не сделали для дальнейшего изучения корректности программ, и что эти методы могут быть неэффективны в реальном языке, основанном на его собственном. В течение следующих шести лет идея CSP
была уточнена в формальное представление того, что называется исчислением процессов, в
попытке взять идеи передачи последовательных процессов и фактически начать
рассуждать о корректности программы. Исчисление процессов — это способ математического моделирования
конкурентных систем, а также предоставляет алгебраические законы для выполнения преобразований в
этих системах для анализа их различных свойств, например, эффективности и корректности.

Хотя исчисление процессов — интересная тема сама по себе, оно выходит за рамки
этой книги. И поскольку исходная статья о CSP и язык, который
развился из нее, в значительной степени послужили источником вдохновения для модели параллелизма Go, именно на них
мы сосредоточимся.

Чтобы поддержать его утверждение о том, что входы и выходы необходимо считать примитивами языка, язык программирования CSP Хоара содержал примитивы для правильного моделирования ввода
и вывода, или связи, между процессами (отсюда и название статьи). Хоар применил термин «процессы» к любой инкапсулированной части
логики, которая требовала ввода для работы и производила вывод, который потребляли бы другие процессы. Хоар, вероятно, мог бы использовать слово «функция», если бы не спор
о том, как структурировать программы, происходящий в сообществе, когда он писал свою статью.
Для связи между процессами Хоар создал команды ввода и вывода: ! для отправки ввода в процесс и ? для чтения вывода из процесса.
Каждая команда должна была указывать либо выходную переменную (в случае чтения переменной из процесса), либо место назначения (в случае отправки ввода в процесс).

Иногда эти два слова относились к одному и тому же, и в этом случае два процесса
считались бы соответствующими. Другими словами, вывод одного процесса
попадал бы непосредственно на ввод другого процесса. В таблице 2-1 показано несколько примеров из
статьи.

![img.png](img/2-1.png)

Сходство с каналами Go очевидно. Обратите внимание, как в последнем примере
выходные данные с запада были отправлены в переменную c, а входные данные с востока были получены из той же
переменной. Эти два процесса соответствуют. В первой статье Хоара по CSP процессы могли общаться только через именованные источники и пункты назначения. Он признал, что это вызовет проблемы со встраиванием кода в качестве библиотеки, поскольку потребители
кода должны будут знать имена входов и выходов. Он небрежно упомянул возможность регистрации того, что он назвал «именами портов», в которых имена
могут быть объявлены в заголовке параллельной команды, что мы, вероятно, распознаем как именованные параметры и именованные возвращаемые значения. Язык также использовал так называемую защищенную команду, которую Эдгар Дейкстра
ввел в предыдущей статье, написанной в 1974 году, «Защищенные команды, неопределенность и формальный вывод программ». Защищенная команда — это просто оператор
с левой и правой частью, разделенный знаком →. Левая часть служила условным выражением или защитой для правой части, поскольку если левая часть была ложной или, в случае
команды, возвращала ложное значение или завершалась, правая часть никогда не выполнялась.

Объединение их с командами ввода-вывода Хоара заложило основу для коммуникационных процессов Хоара и, таким образом, каналов Go.
Используя эти примитивы, Хоар рассмотрел несколько примеров и продемонстрировал,
как язык с первоклассной поддержкой моделирования коммуникации упрощает решение
проблем и делает его более понятным. Некоторые из используемых им обозначений немного
кратки (программисты Perl, вероятно, не согласятся!), но проблемы, которые он представляет,
имеют необычайно ясные решения. Аналогичные решения в Go немного длиннее, но также
несут в себе эту ясность.

История расценила предложение Хоара как правильное; однако интересно отметить,
что до того, как был выпущен Go, лишь немногие языки действительно внесли поддержку этих
примитивов в язык. Большинство популярных языков отдают предпочтение совместному использованию и синхронизации доступа к памяти в стиле передачи сообщений CSP. Есть исключения,
но, к сожалению, они ограничены языками, которые не получили широкого распространения. Go
один из первых языков, включивших принципы CSP в свое ядро ​​и принесших
этот стиль параллельного программирования в массы. Его успех побудил другие языки также попытаться добавить эти примитивы.

Синхронизация доступа к памяти сама по себе не плоха. Позже в этой главе (в разделе «Философия параллелизма Go» на стр. 31) мы увидим, что иногда совместное использование памяти
уместно в определенных ситуациях, даже в Go. Однако модель общей памяти может
быть сложной для правильного использования, особенно в больших или сложных программах. Именно по этой причине параллелизм считается одной из сильных сторон Go: он
был построен с самого начала с учетом принципов CSP, поэтому его легко читать, писать и рассуждать.

## Как это нам поможет?

Вы можете посчитать все это увлекательным или нет, но есть вероятность, что если вы читаете
эту книгу, у вас есть проблемы, которые нужно решить, и вы задаетесь вопросом, почему все это имеет значение.
Что делает Go так по-другому, что отличает его от других популярных языков,
когда дело доходит до параллелизма?

Как мы обсуждали в разделе «Разница между конкурентностью и параллелизмом» на стр. 23 для моделирования параллельных задач, языки обычно заканчивают
свою цепочку абстракций на уровне потока ОС и синхронизации доступа к памяти. Go идет другим путем и заменяет это концепцией горутин
и каналов. Если бы мы провели сравнение между концепциями в двух способах абстрагирования параллельного кода, мы, вероятно, сравнили бы горутину с потоком, а канал с мьютексом (эти примитивы имеют лишь мимолетное сходство, но, надеюсь, сравнение поможет вам сориентироваться). Что делают для нас эти разные абстракции?

Горутины освобождают нас от необходимости думать о нашем проблемном пространстве с точки зрения параллелизма и вместо этого позволяют нам моделировать проблемы ближе к их естественному уровню конкурентности. Хотя мы рассмотрели разницу между параллелизмом и конкурентностью, то, как эта разница влияет на то, как мы моделируем решения, может быть неясно. Давайте перейдем к примеру.

Допустим, мне нужно создать веб-сервер, который обрабатывает запросы на конечной точке. Оставив в стороне фреймворки на мгновение, в языке, который предлагает только абстракцию потоков, я бы, вероятно, размышлял над следующими вопросами:
- Поддерживает ли мой язык потоки естественным образом или мне придется выбирать библиотеку?
- Где должны быть границы ограничения потоков?
- Насколько тяжелы потоки в этой операционной системе?
- Как операционные системы, в которых будет работать моя программа, обрабатывают потоки
по-разному?
- Мне следует создать пул рабочих, чтобы ограничить количество создаваемых мной потоков. Как мне найти оптимальное число?
  
Все это важные вещи для рассмотрения, но ни одна из них напрямую не касается проблемы, которую вы пытаетесь решить. Вас немедленно затянуло в технические детали того, как вы собираетесь решать проблему параллелизма.
Если мы сделаем шаг назад и подумаем о естественной проблеме, мы могли бы сформулировать ее так: отдельные пользователи подключаются к моей конечной точке и открывают сеанс. Сеанс должен
отправить свой запрос и вернуть ответ. В Go мы можем почти напрямую представить естественное состояние этой проблемы в коде: мы создадим горутину для каждого
входящего соединения, отобразим запрос там (потенциально взаимодействуя с другими горутинами для данных/сервисов), а затем вернёмся из функции горутины. То, как мы
естественно думаем о проблеме, напрямую соответствует естественному способу кодирования вещей в
Go. Это достигается обещанием, которое дает нам Go: что горутины легковесны, и нам
обычно не придется беспокоиться о создании одной. Есть подходящие моменты, чтобы рассмотреть, сколько горутинов запущено в вашей системе, но делать это заранее - это, безусловно, преждевременная оптимизация. Сравните это с потоками, где было бы
мудро рассмотреть такие вопросы заранее.

То, что есть фреймворк для языка, который абстрагирует проблемы параллелизма для вас, не означает, что этот естественный способ моделирования параллельных
проблем не имеет значения! Кто-то должен написать фреймворк, и ваш код будет
сидеть поверх любой сложности, с которой пришлось иметь дело автору(ам). То, что сложность скрыта от вас, не означает, что ее нет, а сложность порождает
ошибки. В случае Go язык был разработан вокруг параллелизма, поэтому язык не несовместим с примитивами параллелизма, которые он предоставляет. Это означает меньше
трений и меньше ошибок!

Более естественное отображение в проблемное пространство — это огромное преимущество, но оно также имеет несколько
полезных побочных эффектов. Среда выполнения Go автоматически мультиплексирует горутины в потоки ОС и управляет их планированием для нас. Это означает, что оптимизацию среды выполнения можно выполнять без необходимости изменять то, как мы смоделировали нашу проблему; это классическое разделение интересов. По мере развития параллелизма
среда выполнения Go будет улучшаться, как и производительность вашей программы — все это бесплатно.
Следите за заметками о выпуске Go, и иногда вы увидите такие вещи, как:  
В Go 1.5 порядок планирования горутинов был изменен.

Авторы Go вносят улучшения за кулисами, чтобы сделать вашу программу
быстрее. Такое разделение параллелизма и конкурентности имеет еще одно преимущество: поскольку среда выполнения Go управляет планированием горутин для вас, она может анализировать вещи как горутины, заблокированные в ожидании ввода-вывода, и разумно перераспределяют потоки ОС в горутины, которые не заблокированы. Это также повышает производительность вашего кода. Мы
подробнее обсудим, что делает для вас среда выполнения Go в Главе 6.

Еще одним преимуществом более естественного сопоставления между проблемными пространствами и
кодом Go является вероятное увеличение объема проблемного пространства, смоделированного в конкурентном
образе. Поскольку проблемы, над которыми мы работаем как разработчики, по своей природе
чаще конкурентны, мы, естественно, будем писать конкурентный код на более
тонком уровне детализации, чем, возможно, в других языках; например, если мы вернемся к нашему
примеру с веб-сервером, то теперь у нас будет горутина для каждого пользователя вместо соединений,
мультиплексированных в пул потоков. Этот более тонкий уровень детализации позволяет нашей программе
динамически масштабироваться, когда она работает до возможного уровня параллелизма на хосте программы — закон Амдаля в действии! Это довольно удивительно. И горутины — это только часть головоломки. Другие концепции из CSP, каналы и операторы select, также добавляют ценность.
Например, каналы по своей сути компонуются с другими каналами. Это упрощает написание больших систем, поскольку вы можете координировать ввод из нескольких подсистем, легко компонуя вывод. Вы можете объединять входные каналы
с тайм-аутами, отменами или сообщениями для других подсистем. Координация мьютексов
— гораздо более сложная задача.

Оператор select является дополнением к каналам Go и позволяет выполнять все
сложные части компоновки каналов. Операторы select позволяют вам эффективно ожидать
событий, выбирать сообщение из конкурирующих каналов унифицированным случайным образом, продолжать, если нет ожидающих сообщений, и многое другое.
Этот замечательный гобелен примитивов, вдохновленный CSP, и среда выполнения, которая его поддерживает,
являются тем, что питает Go. Оставшуюся часть книги мы посвятим изучению того, как работают эти вещи, почему и как мы можем использовать их для написания потрясающего кода.

## Философия конкурентности в Go.

CSP был и остается большой частью того, вокруг чего был разработан Go; однако Go также поддерживает более традиционные средства написания параллельного кода с помощью синхронизации доступа к памяти и примитивов, которые следуют этой технике. Структуры и методы в пакетах sync и других позволяют вам выполнять блокировки, создавать пулы ресурсов, вытеснять горутины и многое другое.

Эта возможность выбора между примитивами CSP и синхронизацией доступа к памяти
отлично подходит для вас, поскольку она дает вам немного больше контроля над тем, какой стиль параллельного кода вы выберете для решения проблем, но это также может немного сбивать с толку. У новичков в языке часто складывается впечатление, что стиль параллелизма CSP считается единственным способом писать параллельный код в Go. Например, в
документации по пакету sync говорится:
- Пакет sync предоставляет базовые примитивы синхронизации, такие как блокировки взаимного исключения. За исключением типов Once и WaitGroup, большинство из них предназначены для использования низкоуровневыми библиотечными процедурами. Синхронизация более высокого уровня лучше осуществляется через каналы и
коммуникации.

В FAQ по языку говорится:
- Что касается мьютексов, пакет sync реализует их, но мы надеемся, что стиль программирования Go
побудит людей попробовать более высокоуровневые методы. В частности, рассмотрите возможность структурирования вашей программы таким образом, чтобы только одна горутина в каждый момент времени отвечала за определенный фрагмент данных.
- Не общайтесь через общую память. Вместо этого делитесь памятью через общение.

Существует также множество статей, лекций и интервью, в которых различные члены
основной команды Go поддерживают стиль CSP вместо примитивов, таких как sync.Mutex.

Поэтому вполне понятно, почему команда Go решила
выставить примитивы синхронизации доступа к памяти вообще. Что может быть еще более
запутанным, так это то, что вы увидите примитивы синхронизации, которые широко распространены, увидите, как люди жалуются на чрезмерное использование каналов, а также услышите, как некоторые члены команды Go утверждают, что их можно использовать. Вот цитата из Go Wiki по этому поводу:
- Один из девизов Go — «Делитесь памятью, общаясь, не общайтесь, разделяя память».
- Тем не менее, Go предоставляет традиционные механизмы блокировки в пакете синхронизации. Большинство
проблем блокировки можно решить с помощью каналов или традиционных блокировок.
- Так что же вам следует использовать?
- Используйте то, что наиболее выразительно и/или наиболее просто.
Это хороший совет, и это руководство вы часто видите при работе с Go, но оно
немного расплывчато. Как нам понять, что более выразительно и/или проще?

Какие критерии мы можем использовать? К счастью, есть некоторые ориентиры, которые мы можем использовать, чтобы помочь
нам сделать правильно. Как мы увидим, способ, которым мы можем различать, в основном исходит из того,
где мы пытаемся управлять нашим параллелизмом: внутри в узкой области или снаружи по всей нашей системе. Рисунок 2-1 перечисляет эти ориентиры в дереве решений.

![img.png](img/2-1-figure.png)

Давайте рассмотрим эти точки принятия решений по одной:
- Вы пытаетесь передать право собственности на данные?  

Если у вас есть фрагмент кода, который производит результат, и вы хотите поделиться этим результатом с
другим фрагментом кода, то на самом деле вы передаете право собственности на эти
данные. Если вы знакомы с концепцией владения памятью в языках, которые
не поддерживают сборку мусора, то это та же идея: у данных есть владелец, и
один из способов сделать параллельные программы безопасными — гарантировать, что только один параллельный контекст владеет данными одновременно. Каналы помогают нам передать эту концепцию,
кодируя это намерение в тип канала.

Одним из больших преимуществ этого является то, что вы можете создавать буферизованные каналы для реализации
дешевой очереди в памяти и, таким образом, отделить вашего производителя от потребителя.
Другое заключается в том, что, используя каналы, вы неявно делаете свой параллельный код
компонуемым с другим параллельным кодом.

- Вы пытаетесь защитить внутреннее состояние структуры?  

Это отличный кандидат на примитивы синхронизации доступа к памяти и
достаточно сильный индикатор того, что вам не следует использовать каналы. Используя примитивы синхронизации доступа к памяти, вы можете скрыть детали реализации блокировки
вашей критической секции от ваших вызывающих. Вот небольшой пример типа, который является потокобезопасным, но не раскрывает эту сложность для своих вызывающих:

```go
type Counter struct {
   mu sync.Mutex
   value int
}
func (c *Counter) Increment() {
   c.mu.Lock()
   defer c.mu.Unlock()
   c.value++
}
```

Если вы помните концепцию атомарности, то можно сказать, что мы здесь
определили область атомарности для типа Counter. Вызовы Increment можно
считаь атомарными.

Помните, что ключевое слово здесь — «внутренний». Если вы обнаруживаете, что раскрываете блокировки
за пределами типа, это должно вызвать тревогу. Постарайтесь ограничить блокировки
небольшой лексической областью действия.

- Вы пытаетесь координировать несколько фрагментов логики?

Помните, что каналы по своей сути более компонуемы, чем примитивы синхронизации доступа к памяти. Наличие блокировок, разбросанных по всему объектному графу,
звучит как кошмар, но наличие каналов повсюду ожидается и
поощряется! Я могу компоновать каналы, но я не могу легко компоновать блокировки или методы,
которые возвращают значения.

Вы обнаружите, что вам будет гораздо проще контролировать возникающую сложность,
возникающую в вашем программном обеспечении, если вы используете каналы из-за оператора select в Go и их
способности служить очередями и безопасно передаваться. Если вы обнаружите, что вам трудно понять, как работает ваш параллельный код, почему возникает взаимоблокировка или гонка, и вы используете примитивы, это, вероятно, хороший показатель того, что вам следует переключиться на каналы.
- Это раздел, критически важный для производительности?

Это совершенно не означает: «Я хочу, чтобы моя программа была производительной, поэтому я
буду использовать только мьютексы». Скорее, если у вас есть раздел вашей программы, который вы
пропрофилировали, и он оказывается основным узким местом, которое на порядки медленнее остальной части программы, использование примитивов синхронизации доступа к памяти
может помочь этому критическому разделу работать под нагрузкой. Это связано с тем, что
каналы используют синхронизацию доступа к памяти для работы, поэтому они могут быть только
медленнее. Однако, прежде чем мы даже рассмотрим это, раздел, критически важный для производительности,
может намекать, что нам нужно реструктурировать нашу программу.

Надеюсь, это прояснит, следует ли использовать параллелизм в стиле CSP или синхронизацию доступа к памяти. Существуют другие шаблоны и практики, которые полезны в языках, использующих поток ОС как средство абстрагирования параллелизма. Например, часто возникают такие вещи, как пулы потоков. Поскольку большинство этих абстракций нацелены на сильные и слабые стороны потоков ОС, хорошее практическое правило при работе с Go — отказаться от этих шаблонов. Это не значит, что они бесполезны
вообще, но варианты использования, безусловно, гораздо более ограничены в Go. Придерживайтесь моделирования
проблемного пространства с помощью горутин, используйте их для представления параллельных частей
вашего рабочего процесса и не бойтесь быть либеральными при их запуске. Вам гораздо
вероятнее придется реструктурировать свою программу, чем начать сталкиваться с
верхним пределом того, сколько горутин может поддерживать ваше оборудование.

Философию Go в отношении параллелизма можно резюмировать следующим образом: стремитесь к простоте, используйте
каналы, когда это возможно, и относитесь к горутинам как к бесплатному ресурсу.

---

# Глава 3. Строительные блоки конкурентности в Go

В этой главе мы обсудим богатый набор функций Go, которые поддерживают его историю параллелизма. К концу этой главы вы должны хорошо понимать синтаксис,
функции и пакеты, доступные вам, а также их функциональность.

В этой главе мы обсудим богатый набор функций Go, которые поддерживают его историю параллелизма. К концу этой главы вы должны хорошо понимать синтаксис,
функции и пакеты, доступные вам, а также их функциональность.

## Горутины
Горутины являются одной из самых основных единиц организации в программе Go, поэтому
важно понимать, что они собой представляют и как они работают. Фактически, каждая программа Go имеет по крайней мере одну горутину: основную горутину, которая автоматически создается
и запускается при начале процесса. Почти в любой программе вы, вероятно, рано или поздно обнаружите, что обращаетесь к горутине, чтобы решить свои проблемы. Так что же они такое?

Проще говоря, горутина — это функция, которая выполняется конкурентно (помните:
не обязательно параллельно!) вместе с другим кодом. Вы можете запустить ее, просто поместив
ключевое слово go перед функцией:

```go
func main() {
   go sayHello()
   // continue doing other things
}

func sayHello() {
    fmt.Println("hello")
}
```

Анонимные функции тоже работают! Вот пример, который делает то же самое, что и
предыдущий пример; однако вместо создания горутины из функции, мы создаем
горутину из анонимной функции:

```go
go func() {
    fmt.Println("hello")
}()
// continue doing other things
```

Обратите внимание, что мы должны немедленно вызвать анонимную функцию, чтобы использовать ключевое слово go.

В качестве альтернативы вы можете присвоить функцию переменной и вызвать анонимную функцию
это можно сделать следующим образом:
```go
sayHello := func() {
    fmt.Println("hello")
}
go sayHello()
// continue doing other things
```

Как это круто! Мы можем создать параллельный блок логики с помощью функции и одного ключевого слова! Хотите верьте, хотите нет, но это все, что вам нужно знать для запуска горутин. Можно много сказать о том, как их правильно использовать, синхронизировать и организовывать, но это действительно все, что вам нужно знать, чтобы начать их использовать. Оставшаяся часть этой главы более подробно рассказывает о том, что такое горутины и как они работают. Если вас интересует только написание кода, который правильно работает с горутинами, вы можете
перейти к следующему разделу.

Итак, давайте посмотрим, что происходит за кулисами: как на самом деле работают горутины? Являются ли они потоками ОС? Зелеными потоками? Сколько их мы можем создать?

Горутины уникальны для Go (хотя в некоторых других языках есть похожий примитив параллелизма). Они не являются потоками ОС, и они не совсем зеленые
потоки — потоки, которые управляются средой выполнения языка — они представляют собой более высокий уровень
абстракции, известный как сопрограммы(корутины). Сопрограммы — это просто конкурентные подпрограммы
(функции, замыкания или методы в Go), которые являются невытесняющими — то есть их нельзя
прервать. Вместо этого сопрограммы имеют несколько точек, которые допускают
приостановку или повторный вход.

Что делает горутины уникальными для Go, так это их глубокая интеграция со средой выполнения Go.

Горутины не определяют собственные точки приостановки или повторного входа; среда выполнения Go
наблюдает за поведением горутин во время выполнения и автоматически приостанавливает их, когда они блокируются, а затем возобновляет их, когда они становятся разблокированными. В некотором смысле это делает
их вытесняемыми, но только в точках, где горутина стала заблокированной. Это
изящное партнерство между средой выполнения и логикой горутины. Таким образом, горутины
можно считать особым классом корутин.

Сопрограммы и, следовательно, горутины являются неявно конкурентными конструкциями, но конкурентность не является свойством сопрограммы: что-то должно размещать несколько сопрограмм одновременно и давать каждой возможность выполняться — в противном случае они не
были бы конкурентными! Обратите внимание, что это не означает, что сопрограммы неявно параллельны. Конечно, возможно иметь несколько сопрограмм, выполняющихся последовательно, чтобы создать иллюзию
параллелизма, и на самом деле это происходит все время в Go.

Механизм Go для размещения горутин является реализацией того, что называется планировщиком M:N, что означает, что он сопоставляет M зеленых потоков с N потоками ОС. Затем горутины
планируются на зеленые потоки. Когда у нас больше goroutines, чем зеленых потоков, планировщик обрабатывает распределение goroutines по доступным потокам и обеспечивает, что когда эти goroutines блокируются, другие goroutines могут быть запущены. Мы обсудим, как все это работает, в Главе 6, но здесь мы рассмотрим, как
Go моделирует параллелизм.

Go следует модели параллелизма, называемой моделью fork-join. Слово fork относится к тому факту, что в любой точке программы он может отделить дочернюю ветвь выполнения,
чтобы она выполнялась одновременно с ее родительской. Слово join относится к тому факту, что в какой-то момент в будущем эти параллельные ветви выполнения снова объединятся.
Точка соединения потомка с родительской называется точкой соединения. Вот графическое представление, которое поможет вам это представить:

![img.png](img/3-0.png)

Оператор go указывает, что Go выполняет fork, а ответвленные потоки выполнения — это горутины. Давайте вернемся к нашему простому примеру goroutine:

```go
sayHello := func() {
    fmt.Println("hello")
}
go sayHello()
// continue doing other things
```

Здесь функция sayHello будет запущена в своей собственной goroutine, в то время как остальная часть
программы продолжит выполнение. В этом примере нет точки соединения(join). goroutine,
выполняющая sayHello, просто завершит работу в неопределенное время в будущем, а остальная
часть программы уже продолжит выполнение.

Однако в этом примере есть одна проблема: в том виде, в котором она написана, не определено,
будет ли вообще когда-либо запущена функция sayHello. goroutine будет создана
и запланирована с использованием среды выполнения Go для выполнения, но на самом деле она может не получить возможности
запуститься до выхода из основной goroutine.

Действительно, поскольку мы опускаем остальную часть основной функции для простоты, когда
мы запускаем этот небольшой пример, почти наверняка программа завершит выполнение
до того, как goroutine, размещающая вызов sayHello, когда-либо будет запущена. В результате вы не увидите слово «hello», выведенное на stdout. Вы можете поместить time.Sleep после создания goroutine, но помните, что это на самом деле не создает точку соединения, а только состояние гонки. Если вы вспомните Главу 1, вы увеличите вероятность того, что goroutine
будет запущена до выхода, но вы не гарантируете этого. Точки соединения гарантируют корректность нашей
программы и устраняют состояние гонки.

Чтобы создать точку соединения, вам нужно синхронизировать основную goroutine и goroutine sayHello. Это можно сделать несколькими способами, но я буду использовать тот, о котором мы поговорим в «Пакете sync» на странице 47: sync.WaitGroup. Сейчас неважно понимать, как этот пример создает точку соединения, важно только то, что он создает ее
между двумя goroutine. Вот правильная версия нашего примера:

```go
var wg sync.WaitGroup

sayHello := func() {
   defer wg.Done()
   fmt.Println("hello")
}

wg.Add(1)
go sayHello()
wg.Wait() // 1
```

1) Точка слияния горутин (join point)

Результат выполения программы:
```hello```

Этот пример детерминированно заблокирует основную goroutine до тех пор, пока goroutine,
содержащая функцию sayHello, не завершится. Вы узнаете, как работает sync.WaitGroup в
«Пакет sync» на стр. 47, но чтобы сделать наши примеры правильными, я начну использовать его
для создания точек соединения.
Мы использовали много анонимных функций в наших примерах для создания быстрых
примеров goroutine. Давайте переключим наше внимание на замыкания. Замыкания замыкаются вокруг
лексической области, в которой они созданы, тем самым захватывая переменные. Если вы запускаете замыкание в goroutine, работает ли замыкание с копией этих переменных или исходными ссылками? Давайте попробуем и посмотрим:

```go
var wg sync.WaitGroup
salutation := "hello"
wg.Add(1)

go func() {
   defer wg.Done()
   salutation = "welcome" // 1
}()

wg.Wait()
fmt.Println(salutation)
```
1) Здесь мы видим горутину, изменяющую значение переменной salutation

Как вы думаете, какое значение будет у приветствия: «hello» или «welcome»? Давайте запустим его
и выясним:
``welcome``

Интересно! Оказывается, горутины выполняются в том же адресном пространстве(Области видимости), в котором они
были созданы, и поэтому наша программа выводит слово «welcome». Давайте попробуем другой
пример. Как вы думаете, что выведет эта программа?

```go
var wg sync.WaitGroup
for _, salutation := range []string{"hello", "greetings", "good day"} {
   wg.Add(1)
   go func() {
      defer wg.Done()
      fmt.Println(salutation)
   }()
}
wg.Wait()
```

Ответ сложнее, чем большинство людей ожидают, и это одна из немногих удивительных вещей в Go. Большинство людей интуитивно думают, что это выведет слова «hello»,
«greetings» и «good day» в каком-то неопределенном порядке, но посмотрите, что мы получим:
```
good day
good day
good day
```

Это немного удивительно! Давайте выясним, что здесь происходит. В этом примере
го-программа запускает замыкание, которое замкнуло переменную итерации salutation,
которая имеет тип string. По мере итерации нашего цикла salutation присваивается
следующему строковому значению в литерале среза. Поскольку запланированные горутины могут быть запущены
в любой момент времени в будущем, неизвестно, какие значения будут выведены из
го-программы. На моем компьютере существует высокая вероятность выхода из цикла
до начала горутины. Это означает, что переменная salutation выходит из
области действия. Что тогда произойдет? Могут ли горутины по-прежнему ссылаться на что-то, что вышло из области действия? Не будут ли горутины обращаться к памяти, которая потенциально
была удалена сборщиком мусора?

Это интересное замечание о том, как Go управляет памятью. Среда выполнения Go достаточно
наблюдательна, чтобы знать, что ссылка на переменную приветствия все еще
хранится, и поэтому перенесет память в кучу, чтобы горутины могли
продолжать к ней обращаться.

Обычно на моей машине цикл завершается до того, как начинают работать какие-либо горутины, поэтому
приветствие переносится в кучу, содержащую ссылку на последнее значение в моем
строковом фрагменте, «good day». И поэтому я обычно вижу «good day» напечатанным три раза.

Правильный способ написать этот цикл — передать копию приветствия в замыкание, чтобы к моменту запуска горутины она работала с данными из своей итерации
цикла:

```go
var wg sync.WaitGroup
for _, salutation := range []string{"hello", "greetings", "good day"} {
   wg.Add(1)
   go func(salutation string) { // 1
      defer wg.Done()
      fmt.Println(salutation)
   }(salutation) // 2
}
wg.Wait()
```
1) Здесь мы объявляем параметр, как и в любой другой функции. Мы затеняем исходную
   переменную приветствия, чтобы сделать происходящее более очевидным.
2) Здесь мы передаем переменную текущей итерации в замыкание. Копия структуры строки
   создается, тем самым гарантируя, что при запуске goroutine мы ссылаемся на правильную строку.

И как мы видим, мы получаем ожидаемый и корректный вывод:

```
good day
hello
greetings
```

Этот пример ведет себя так, как мы и ожидали, и лишь немного более многословен.

Поскольку горутины работают в одном адресном пространстве друг с другом и просто
хостят функции, использование горутин является естественным расширением для написания неконкурентного
кода. Компилятор Go прекрасно заботится о закреплении переменных в памяти, чтобы горутины случайно не обращались к освобожденной памяти, что позволяет разработчикам сосредоточиться на
своем проблемном пространстве, а не на управлении памятью; однако, это не пустой чек.

Поскольку несколько горутин могут работать с одним и тем же адресным пространством, нам все равно придется
беспокоиться о синхронизации. Как мы уже обсуждали, мы можем либо синхронизировать доступ к общей памяти, к которой обращаются горутины, либо использовать примитивы CSP для совместного использования памяти путем связи. Мы обсудим эти методы позже в главе «Каналы» на странице 64 и «Пакет синхронизации» на странице 47.

Еще одно преимущество горутин в том, что они необычайно легкие. Вот отрывок из часто задаваемых вопросов по Go:

"Новоиспеченной горутине выделяется несколько килобайт, чего почти всегда достаточно.
Когда этого не происходит, среда выполнения автоматически увеличивает (и уменьшает) память для хранения стека, позволяя многим горутинам жить в скромном объеме памяти. Накладные расходы ЦП составляют в среднем около трех дешевых инструкций на вызов функции. Практично создавать сотни тысяч горутин в одном адресном пространстве. Если бы горутины были просто потоками, системные ресурсы исчерпывались бы при гораздо меньшем количестве."

Несколько килобайт на горутину; это совсем неплохо! Давайте попробуем убедиться в этом сами. Но прежде чем мы это сделаем, нам нужно рассмотреть одну интересную вещь о горутинах: сборщик мусора ничего не делает для сбора горутин, которые были заброшены по какой-то причине. Если я напишу следующее:

```go
go func() {
// <Операция, которая заблокирует горутину навсегда>
}()
// Do work
```

Горутина здесь будет висеть до тех пор, пока процесс не завершится. Мы обсудим, как решить эту проблему в Главе 4 в разделе «Предотвращение утечек горутин» на странице 90.
Мы используем это в своих интересах в следующем примере, чтобы фактически измерить размер горутины.

В следующем примере мы объединяем тот факт, что горутины не подвергаются сборке мусора, со способностью среды выполнения проводить самоанализ и измерять объем памяти, выделенной до и после создания горутины:

```go
memConsumed := func() uint64 {
   runtime.GC()
   var s runtime.MemStats
   runtime.ReadMemStats(&s)
   return s.Sys
}

var c <-chan interface{}
var wg sync.WaitGroup
noop := func() { wg.Done(); <-c } // 1

const numGoroutines = 1e4 // 2
wg.Add(numGoroutines)
before := memConsumed() // 3
for i := numGoroutines; i > 0; i-- {
   go noop()
}

wg.Wait()
after := memConsumed() // 4
fmt.Printf("%.3fkb", float64(after-before)/numGoroutines/1000)
```

1) Нам нужна горутина, которая никогда не завершится, чтобы мы могли хранить их
   в памяти для измерения. Не беспокойтесь о том, как мы этого достигнем в данный момент; просто знайте, что эта горутина не завершится, пока процесс не будет завершен.
2) Здесь мы определяем количество создаваемых горутин. Мы будем использовать закон больших чисел, чтобы асимптотически приблизиться к размеру горутины. (Создаем большое число горутин, и потом вычисляем средний объем)
3) Здесь мы измеряем объем памяти, потребляемой до создания наших горутин.
4) И здесь мы измеряем объем памяти, потребляемой после создания наших
   горутин.

Результат наших вычислений:
``2.817kb``

Похоже, документация верна! Это просто пустые горутины, которые ничего не делают, но это все равно дает нам представление о количестве горутин, которые мы, скорее всего,
создадим. Таблица 3-1 дает некоторые грубые оценки того, сколько горутин вы, скорее всего,
создадите с 64-битным ЦП без использования swap space.

![img.png](img/3-1-table.png)

Эти цифры довольно большие! На моем ноутбуке у меня 8 ГБ оперативной памяти, что означает, что
теоретически я могу запустить миллионы горутин без необходимости подкачки. Конечно,
это игнорирует другие вещи, запущенные на моем компьютере, и фактическое содержимое
горутин, но этот быстрый расчет показывает, насколько горутины легковесны!
Что может испортить нам настроение, так это переключение контекста, когда что-то, размещающее конкурентный процесс, должно сохранить свое состояние, чтобы переключиться на выполнение другого параллельного процесса. Если у нас слишком много конкурентных процессов, мы можем потратить все время ЦП на переключение контекста между ними и так и не выполнить никакой реальной работы. На уровне ОС с потоками это может быть довольно затратно. Поток ОС должен сохранять такие вещи, как значения регистров, таблицы поиска и карты памяти, чтобы успешно переключиться обратно на текущий поток, когда придет время. Затем он должен загрузить ту же информацию
для входящего потока.

Переключение контекста в программном обеспечении сравнительно намного, намного дешевле. При программно-определяемом планировщике среда выполнения может быть более избирательной в том, что сохраняется для
извлечения, как это сохраняется и когда возникает необходимость сохранения. Давайте посмотрим на
относительную производительность переключения контекста на моем ноутбуке между потоками ОС и
горутинами. Сначала мы используем встроенный в Linux набор бенчмарков, чтобы измерить,
сколько времени требуется для отправки сообщения между двумя потоками на одном ядре:
```shell
taskset -c 0 perf bench sched pipe -T
```
Результат:
```
# Running 'sched/pipe' benchmark:
# Executed 1000000 pipe operations between two threads
Total time: 2.935 [sec]
2.935784 usecs/op
340624 ops/sec
```

Этот бенчмарк на самом деле измеряет время, необходимое для отправки и получения сообщения в потоке, поэтому мы возьмем результат и разделим его на два. Это дает нам 1,467 мкс на переключение контекста. Это не кажется слишком плохим, но давайте отложим суждение, пока не изучим переключения контекста между горутинами.
Мы построим аналогичный бенчмарк с использованием Go. Я использовал несколько вещей, которые мы еще не обсуждали, поэтому, если что-то сбивает с толку, просто следуйте выноскам и сосредоточьтесь на результате.
В следующем примере будут созданы две горутины и отправлено сообщение между ними:

```go
func BenchmarkContextSwitch(b *testing.B) {
   var wg sync.WaitGroup
   begin := make(chan struct{})
   c := make(chan struct{})
   var token struct{}
   
   sender := func() {
      defer wg.Done()
      <-begin // 1
      for i := 0; i < b.N; i++ {
       c <- token // 2
      }
   }
   
   receiver := func() {
      defer wg.Done()
      <-begin // 1
      for i := 0; i < b.N; i++ {
          <-c // 3
      }
   }
   
   wg.Add(2)
   go sender()
   go receiver()
   b.StartTimer() // 4
   close(begin) // 5
   wg.Wait()
}
```

1) Здесь мы ждем, пока нам не скажут начать. Мы не хотим, чтобы стоимость настройки и запуска каждой горутины учитывалась в измерении переключения контекста.
2) Здесь мы отправляем сообщения в горутину-получатель. Структура {}{} называется
   пустой структурой и не занимает памяти; таким образом, мы измеряем только время, необходимое для передачи сообщения.
3) Здесь мы получаем сообщение, но ничего с ним не делаем.
4) Здесь мы запускаем таймер производительности.
5) Здесь мы говорим двум горутинам начать.

Мы запускаем бенчмарк, указав, что мы хотим использовать только один процессор, чтобы это был
аналогичный тест бенчмарку Linux. Давайте посмотрим на результаты:

```go
go test -bench=. -cpu=1 \
src/gos-concurrency-building-blocks/goroutines/fig-ctx-switch_test.go
```

```
BenchmarkContextSwitch 5000000 225 ns/op  
PASS  
ok command-line-arguments 1.393s
```

225 нс на переключение контекста, вау! Это 0,225 мкс, или на 92% быстрее, чем переключение контекста ОС на моей машине, которое, если вы помните, заняло 1,467 мкс. Трудно делать какие-либо заявления о том, сколько горутин вызовет слишком много переключений контекста, но мы можем
с уверенностью сказать, что верхний предел, скорее всего, не будет каким-либо препятствием для использования
горутин.

Прочитав этот раздел, вы теперь должны понимать, как запускать горутины, и немного о том, как они работают. Вы также должны быть уверены, что можете безопасно создать
горутину в любое время, когда почувствуете, что проблемное пространство того требует. Как мы обсуждали в разделе «Разница между параллелизмом и многопоточностью» на странице 23, чем больше goroutines вы создаете, и если ваше проблемное пространство не ограничено одним параллельным сегментом по закону Амдаля, тем больше ваша программа будет масштабироваться с несколькими процессорами. Создание goroutines обходится очень дешево, и поэтому вам следует обсуждать их стоимость только в том случае, если вы доказали, что они являются основной причиной проблемы производительности.

## Пакет sync

Пакет sync содержит примитивы конкурентности, которые наиболее полезны для низкоуровневой синхронизации доступа к памяти. Если вы работали с языками, которые в первую очередь
обрабатывают параллелизм через синхронизацию доступа к памяти, эти типы, скорее всего,
уже будут вам знакомы. Разница между этими языками в Go заключается в том, что Go
создал новый набор примитивов конкурентности поверх примитивов синхронизации доступа к памяти, чтобы предоставить вам расширенный набор вещей для работы. Как мы
обсуждали в «Философии конкурентности Go» на стр. 31, эти операции
имеют свое применение — в основном в небольших областях, таких как структура. Вам придется решать,
когда синхронизация доступа к памяти уместна. С учетом сказанного,
давайте начнем рассматривать различные примитивы, которые предоставляет пакет sync. 

### WaitGroup

WaitGroup — отличный способ дождаться завершения набора конкурентных операций, когда
вам не важен результат конкретной операции или у вас есть другие
средства сбора их результатов. Если ни одно из этих условий не выполняется, я предлагаю вам
использовать каналы и оператор select. WaitGroup настолько полезен, что я представляю его
сначала, чтобы использовать его в последующих разделах. Вот простой пример использования
WaitGroup для ожидания завершения горутин:

```go
var wg sync.WaitGroup
wg.Add(1) // 1
go func() {
   defer wg.Done() // 2
   fmt.Println("1st goroutine sleeping...")
   time.Sleep(1)
}()

wg.Add(1) // 1
go func() {
   defer wg.Done() // 2
   fmt.Println("2nd goroutine sleeping...")
   time.Sleep(2)
}()

wg.Wait() // 3
fmt.Println("All goroutines complete.")
```

1) Вызов Add с аргументом 1 для индикации что одна горутина стартовала
2) Здесь мы вызываем Done, используя ключевое слово defer, чтобы гарантировать, что перед выходом из замыкания goroutine мы укажем WaitGroup, что мы вышли.
3) Здесь мы вызываем Wait, который блокирует основную горутину до тех пор, пока все горутины не сообщат, что они вышли.

Результат:
```
2nd goroutine sleeping...
1st goroutine sleeping...
All goroutines complete.
```

WaitGroup можно представить как параллельный безопасный счетчик: вызовы Add увеличивают счетчик на переданное целое число, а вызовы Done уменьшают счетчик на единицу.

Вызовы Wait блокируются, пока счетчик не станет равным нулю.

Обратите внимание, что вызовы Add выполняются вне goroutines, которые они помогают отслеживать. Если бы мы этого не сделали, мы бы ввели состояние гонки, потому что, как вы помните из раздела «Goroutines» на странице 37, у нас нет никаких гарантий, когда goroutines
будут запланированы; мы могли бы достичь вызова Wait до того, как начнется любая из goroutines. Если бы вызовы Add были помещены внутрь замыканий goroutines, вызов Wait
мог бы вернуться без блокировки вообще, потому что вызовы Add не
были бы выполнены.

Обычно вызовы Add связывают как можно ближе к goroutines, которые они
помогают отслеживать, но иногда вы можете обнаружить, что Add вызывается для отслеживания группы goroutines
всех одновременно. Я обычно делаю это перед циклами for, например так:

```go
hello := func(wg *sync.WaitGroup, id int) {
   defer wg.Done()
   fmt.Printf("Hello from %v!\n", id)
}

const numGreeters = 5
var wg sync.WaitGroup
wg.Add(numGreeters)

for i := 0; i < numGreeters; i++ {
    go hello(&wg, i+1)
}
wg.Wait()
```

Результат:
```
Hello from 5!
Hello from 4!
Hello from 3!
Hello from 2!
Hello from 1!
```

### Mutex и RWMutex

Если вы уже знакомы с языками, которые обрабатывают параллелизм посредством синхронизации доступа к памяти, то вы, вероятно, сразу узнаете Mutex. Если вы не относите себя к этой группе, не волнуйтесь, Mutex очень прост в понимании.
Mutex означает «взаимное исключение» и является способом защиты критических разделов вашей
программы. Если вы помните из Главы 1, критический раздел — это область вашей программы, которая требует исключительного доступа к общему ресурсу. Mutex предоставляет
безопасный для одновременного выполнения способ выражения исключительного доступа к этим общим ресурсам. Если заимствовать
Goism, то в то время как каналы разделяют память, общаясь, Mutex разделяет память, создавая соглашение, которому разработчики должны следовать для синхронизации доступа к
памяти. Вы несете ответственность за координацию доступа к этой памяти, защищая
доступ к ней с помощью мьютекса. Вот простой пример двух go-программ, которые пытаются увеличить и уменьшить общее значение; они используют Mutex для синхронизации
доступа:

```go
var count int
var lock sync.Mutex
increment := func() {
   lock.Lock() // 1
   defer lock.Unlock() // 2
   count++
   fmt.Printf("Incrementing: %d\n", count)
}

decrement := func() {
   lock.Lock() // 1
   defer lock.Unlock() // 2
   count--
   fmt.Printf("Decrementing: %d\n", count)
}
// Increment
var arithmetic sync.WaitGroup
for i := 0; i <= 5; i++ {
   arithmetic.Add(1)
   go func() { 
      defer arithmetic.Done()
      increment()
   }()
}
// Decrement
for i := 0; i <= 5; i++ {
   arithmetic.Add(1)
   go func() {
      defer arithmetic.Done()
      decrement()
   }()
}
arithmetic.Wait()
fmt.Println("Arithmetic complete.")
```

1) Здесь мы запрашиваем исключительное использование критической секции — в данном случае переменной count — защищенной Mutex, lock.
2) Здесь мы указываем, что мы закончили с критической секцией и выполняем unlock.

Результат:
```go
Decrementing: -1
Incrementing: 0
Decrementing: -1
Incrementing: 0
Decrementing: -1
Decrementing: -2
Decrementing: -3
Incrementing: -2
Decrementing: -3
Incrementing: -2
Incrementing: -1
Incrementing: 0
Arithmetic complete.
```

Вы заметите, что мы всегда вызываем Unlock в операторе defer. Это очень распространенная идиома при использовании Mutex, чтобы гарантировать, что вызов всегда будет выполнен, даже при панике. Невыполнение этого требования, вероятно, приведет к тупиковой ситуации в вашей программе. Критические разделы так называются, потому что они отражают узкое место в вашей программе. Вход в критический раздел и выход из него обходятся
несколько дорого, поэтому обычно люди
пытаются минимизировать время, проведенное в критических разделах.

Одной из стратегий для этого является уменьшение поперечного сечения критического раздела.
Может быть память, которую необходимо разделить между несколькими параллельными процессами, но,
возможно, не все эти процессы будут читать и писать в эту память. Если это так, вы можете воспользоваться другим типом мьютекса: sync.RWMutex.

Sync.RWMutex концептуально то же самое, что и Mutex: он защищает доступ к
памяти; Однако RWMutex дает вам немного больше контроля над памятью. Вы
можете запросить блокировку для чтения, в этом случае вам будет предоставлен доступ, если только
блокировка не удерживается для записи. Это означает, что произвольное количество читателей может
удерживать блокировку чтения, пока ничто другое не удерживает блокировку записи. Вот пример,
демонстрирующий производителя, который менее активен, чем многочисленные потребители,
создаваемые кодом:

```go
producer := func(wg *sync.WaitGroup, l sync.Locker) { // 1
   defer wg.Done()
   for i := 5; i > 0; i-- {
      l.Lock()
      l.Unlock()
      time.Sleep(1) // 2
   }
}
observer := func(wg *sync.WaitGroup, l sync.Locker) {
   defer wg.Done()
   l.Lock()
   defer l.Unlock()
}

test := func(count int, mutex, rwMutex sync.Locker) time.Duration {
   var wg sync.WaitGroup
   wg.Add(count+1)
   beginTestTime := time.Now()
   
   go producer(&wg, mutex)
   for i := count; i > 0; i-- {
    go observer(&wg, rwMutex)
   }
   wg.Wait()
   
   return time.Since(beginTestTime)
}

tw := tabwriter.NewWriter(os.Stdout, 0, 1, 2, ' ', 0)
defer tw.Flush()
var m sync.RWMutex
fmt.Fprintf(tw, "Readers\tRWMutext\tMutex\n")

for i := 0; i < 20; i++ {
   count := int(math.Pow(2, float64(i)))
   fmt.Fprintf(
      tw,
      "%d\t%v\t%v\n",
      count,
      test(count, &m, m.RLocker()),
      test(count, &m, &m),
   )
}
```
1) Второй параметр функции производителя имеет тип sync.Locker. Этот интерфейс имеет два метода, Lock и Unlock, которым удовлетворяют типы Mutex и RWMutex.
2) Здесь мы заставляем производителя спать на одну секунду, чтобы сделать его менее активным, чем
   observer горутину.

Результат:

```go
Readers RWMutext     Mutex
1       38.343µs     15.854µs
2       21.86µs      13.2µs
4       31.01µs      31.358µs
8       63.835µs     24.584µs
16      52.451µs     78.153µs
32      75.569µs     69.492µs
64      141.708µs    163.43µs
128     176.35µs     157.143µs
256     234.808µs    237.182µs
512     262.186µs    434.625µs
1024    459.349µs    850.601µs
2048    840.753µs    1.663279ms
4096    1.683672ms   2.42148ms
8192    2.167814ms   4.13665ms
16384   4.973842ms   8.197173ms
32768   9.236067ms   16.247469ms
65536   16.767161ms  30.948295ms
131072  71.457282ms  62.203475ms
262144  158.76261ms  119.634601ms
524288  303.865661ms 231.072729ms
```

Вы можете видеть на этом конкретном примере, что сокращение поперечного сечения нашей критической секции действительно начинает окупаться только около 213 читателей. Это будет зависеть от того,
что делает ваша критическая секция, но обычно рекомендуется использовать RWMutex вместо
Mutex, когда это логически имеет смысл.

## Cond
Комментарий к типу Cond действительно отлично описывает его назначение:
- ...точка встречи для горутин, ожидающих или объявляющих о возникновении
  события.

В этом определении «событие» — это любой произвольный сигнал между двумя или более горутинами,
который не несет никакой информации, кроме того факта, что он произошел. Очень часто вам
захочется дождаться одного из этих сигналов, прежде чем продолжить выполнение горутины. Если
мы посмотрим, как это сделать без типа Cond, один наивный подход к этому — использовать бесконечный цикл:

```go
for conditionTrue() == false {
}
```
Однако это потребляло бы все циклы одного ядра. Чтобы исправить это, мы могли бы ввести
time.Sleep:

```go
for conditionTrue() == false {
    time.Sleep(1*time.Millisecond)
}
```

Это лучше, но все еще неэффективно, и вам придется выяснить, как долго спать:
слишком долго, и вы искусственно ухудшаете производительность; слишком коротко, и вы без необходимости потребляете слишком много процессорного времени. Было бы лучше, если бы был какой-то способ для goroutine эффективно спать, пока она не получит сигнал проснуться и проверить свое состояние. Это именно то, что делает для нас тип Cond. Используя Cond, мы могли бы написать
предыдущие примеры так:
```go
c := sync.NewCond(&sync.Mutex{}) // 1
c.L.Lock() // 2
for conditionTrue() == false {
   c.Wait() // 3
}
c.L.Unlock() // 4
```
1) Здесь мы создаем новый Cond. Функция NewCond принимает тип, который удовлетворяет интерфейсу sync.Locker. Это то, что позволяет типу Cond облегчать
координацию с другими goroutines безопасным для одновременного выполнения способом.
2) Здесь мы блокируем Locker для этого состояния. Это необходимо, потому что вызов Wait автоматически вызывает Unlock для Locker при входе.
3) Здесь мы ждем уведомления о возникновении состояния. Это блокирующий
   вызов, и goroutine будет приостановлена.
4) Здесь мы разблокируем Locker для этого состояния. Это необходимо, потому что при выходе из Wait он вызывает Lock в Locker для состояния.

Этот подход гораздо эффективнее. Обратите внимание, что вызов Wait не просто блокирует, он
приостанавливает текущую goroutine, позволяя другим goroutine работать в потоке ОС.

При вызове Wait происходит еще несколько вещей: при входе Wait вызывается Unlock для
переменной Cond Locker, а при выходе Wait вызывается Lock для
переменной Cond Locker. По моему мнению, к этому нужно немного привыкнуть; это фактически скрытый побочный
эффект метода. Кажется, что мы удерживаем эту блокировку все время, пока ждем
выполнения условия, но на самом деле это не так. Когда вы сканируете код, вам просто нужно следить за этим шаблоном.

Давайте расширим этот пример и покажем обе стороны уравнения: goroutine, которая
ожидает сигнала, и goroutine, которая отправляет сигналы. Допустим, у нас есть очередь
фиксированной длины 2 и 10 элементов, которые мы хотим поместить в очередь. Мы хотим ставить
элементы в очередь, как только появится место, поэтому мы хотим получать уведомления, как только появится место в
очереди. Давайте попробуем использовать Cond для управления этой координацией:

```go
c := sync.NewCond(&sync.Mutex{}) // 1
queue := make([]interface{}, 0, 10) // 2

removeFromQueue := func(delay time.Duration) {
   time.Sleep(delay)
   c.L.Lock() // 8
   queue = queue[1:] // 9
   fmt.Println("Removed from queue")
   c.L.Unlock() // 10 
   c.Signal() // 11
}

for i := 0; i < 10; i++{
   c.L.Lock() // 3
   for len(queue) == 2 { // 4
    c.Wait() // 5
   }
   fmt.Println("Adding to queue")
   queue = append(queue, struct{}{})
   go removeFromQueue(1*time.Second) // 6
   c.L.Unlock() // 7
}
```

1) Сначала мы создаем наше условие, используя стандартный sync.Mutex в качестве Locker.
2) Затем мы создаем срез с длиной ноль. Поскольку мы знаем, что в конечном итоге добавим
   10 элементов, мы создаем его экземпляр с емкостью 10.
3) Мы входим в критическую секцию для условия, вызывая Lock для Locker
   условия.
4) Здесь мы проверяем длину очереди в цикле. Это важно, потому что сигнал по условию не обязательно означает, что то, чего вы ждали, произошло, — только то, что что-то произошло.
5) Мы вызываем Wait, который приостанавливает основную горутину, пока не будет отправлен сигнал по условию.
6) Здесь мы создаем новую горутину, которая будет удалять элемент из очереди через одну секунду.
7) Здесь мы выходим из критической секции условия, поскольку мы успешно поставили
   элемент в очередь.
8) Мы снова входим в критическую секцию для условия, чтобы мы могли изменить данные,
   относящиеся к условию.
9) Здесь мы имитируем удаление элемента из очереди, переназначая заголовок среза
   второму элементу.
10) Здесь мы выходим из критической секции условия, поскольку мы успешно удалили
    элемент из очереди.
11) Здесь мы даем знать goroutine, ожидающей условия, что что-то произошло.

Вывод:
```go
Adding to queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
```

Как вы можете видеть, программа успешно добавляет все 10 элементов в очередь (и завершает работу,
прежде чем у нее появится возможность вывести из очереди последние два элемента). Она также всегда ждет, пока хотя бы
один элемент не будет выведен из очереди, прежде чем ставить в очередь другой.

В этом примере у нас также есть новый метод Signal. Это один из двух методов,
которые тип Cond предоставляет для уведомления goroutines, заблокированных при вызове Wait, о том, что условие было запущено. Другой метод называется Broadcast. Внутри среда выполнения поддерживает список FIFO goroutines, ожидающих сигнала; Signal находит goroutine, которая ждала дольше всего, и уведомляет об этом, тогда как Broadcast отправляет
сигнал всем goroutines, которые ждут. Broadcast,
возможно, более интересен из двух методов, поскольку он предоставляет способ общения с несколькими goroutines одновременно. Мы можем тривиально воспроизвести Signal с каналами (как мы увидим в разделе
«Каналы» на странице 64), но воспроизведение поведения повторных вызовов Broadcast
было бы сложнее. Кроме того, тип Cond гораздо более производительный, чем
использование каналов.

Чтобы почувствовать, каково это использовать Broadcast, представим, что мы создаем приложение GUI с кнопкой на нем. Мы хотим зарегистрировать произвольное количество функций,
которые будут запускаться при нажатии этой кнопки. Cond идеально подходит для этого, потому что мы можем использовать
его метод Broadcast для уведомления всех зарегистрированных обработчиков. Давайте посмотрим, как это может выглядеть:

```go
type Button struct { // 1
    Clicked *sync.Cond
}
button := Button{ Clicked: sync.NewCond(&sync.Mutex{}) }
subscribe := func(c *sync.Cond, fn func()) { // 2
   var goroutineRunning sync.WaitGroup
   goroutineRunning.Add(1)
   go func() {
      goroutineRunning.Done()
      c.L.Lock()
      defer c.L.Unlock()
      c.Wait()
      fn()
   }()
   goroutineRunning.Wait()
}

var clickRegistered sync.WaitGroup // 3
clickRegistered.Add(3)

subscribe(button.Clicked, func() { // 4
   fmt.Println("Maximizing window.")
   clickRegistered.Done()
})
subscribe(button.Clicked, func() { // 5
   fmt.Println("Displaying annoying dialog box!")
   clickRegistered.Done()
})
subscribe(button.Clicked, func() { // 6
   fmt.Println("Mouse clicked.")
   clickRegistered.Done()
})

button.Clicked.Broadcast() // 7
clickRegistered.Wait()
```
1) Мы определяем тип Button, который содержит условие Clicked.
2) Здесь мы определяем удобную функцию, которая позволит нам регистрировать функции для обработки сигналов из условия. Каждый обработчик запускается в своей собственной goroutine, и
   subscribe не выйдет, пока не будет подтверждено, что эта goroutine запущена.
3) Здесь мы устанавливаем обработчик для момента, когда кнопка мыши поднята. Он, в свою очередь, вызывает Broadcast для Clicked Cond, чтобы сообщить всем обработчикам, что кнопка мыши
   была нажата (более надежная реализация сначала проверит, что она
   была нажата).
4) Здесь мы создаем WaitGroup. Это делается только для того, чтобы гарантировать, что наша программа не завершится,
   прежде чем произойдут наши записи в stdout.
5) Здесь мы регистрируем обработчик, который имитирует максимизацию окна кнопки при нажатии кнопки.
6) Здесь мы регистрируем обработчик, который имитирует отображение диалогового окна при щелчке мыши.
7) Затем мы имитируем пользователя, который отпустил кнопку мыши после щелчка кнопки приложения.